{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electrolyzer Data Exploratoy Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "    \n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, Conv1D, Flatten, Dense, Reshape, Conv1DTranspose\n",
    "from keras.models import Model\n",
    "from keras.models import clone_and_build_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from helper_function import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaskPredModel(InputFeature):\n",
    "    # Define input layer\n",
    "    input_layer = Input(shape=(InputFeature.shape[1], InputFeature.shape[2]))\n",
    "    \n",
    "    # Encoder part\n",
    "    input_layer = Input(shape=(InputFeature.shape[1], InputFeature.shape[2]))\n",
    "    x = Conv1D(32, 3, activation='relu', padding='same')(input_layer)\n",
    "    x = Conv1D(32, 3, activation='relu', padding='same')(x)\n",
    "    shape1=x.get_shape()[1:]\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    ##### First head for masked ouput prediction (linear)\n",
    "    d1 = Reshape(shape1)(x)\n",
    "    d1 = Conv1DTranspose(32, 3, strides=1, activation='relu', padding='same')(d1)\n",
    "    d1 = Conv1DTranspose(6, 3, strides=1, activation='linear', padding='same')(d1)\n",
    "\n",
    "    ##### Second head for masked ouput prediction (boolean)\n",
    "    d2 = Reshape(shape1)(x)\n",
    "    d2 = Conv1DTranspose(32, 3, strides=1, activation='relu', padding='same')(d2)\n",
    "    d2 = Conv1DTranspose(6, 3, strides=1, activation='sigmoid', padding='same')(d2)\n",
    "    \n",
    "    # Define the autoencoder model\n",
    "    autoencoder = Model(input_layer, [d1,d2])\n",
    "\n",
    "    # Compile the model with mean squared error (MSE) loss function and Adam optimizer\n",
    "    autoencoder.compile(loss=['mean_squared_error','binary_crossentropy'], optimizer='adam')\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "data = pd.read_csv(\"Electrolyzer_faults.csv\")\n",
    "X,Y,Z = sliding_window(data, window_size=10, stride=1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "X_sc=sc.fit_transform(X.reshape(-1,X.shape[2])).reshape(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, z_train, z_test = train_test_split(X_sc, Z, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOTA-2: Masked prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_data(X, mask_percentage=0.10):\n",
    "    X_masked = np.zeros(X.shape)\n",
    "    Mask = np.zeros(X.shape)\n",
    "    for i,x in enumerate(X):\n",
    "        binary_mask = np.random.choice([1, 0], size=x.shape, p=[1 - mask_percentage, mask_percentage])\n",
    "        x_masked = x * binary_mask\n",
    "        X_masked[i] = x_masked\n",
    "        Mask[i] = binary_mask\n",
    "    return X_masked, Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_mask,train_mask = mask_data(x_train, mask_percentage=0.10)\n",
    "x_test_mask,test_mask = mask_data(x_test, mask_percentage=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining using hybrid method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "29/29 [==============================] - 3s 19ms/step - loss: 0.4987 - binary_accuracy: 0.8334 - val_loss: 0.2968 - val_binary_accuracy: 0.9269\n",
      "Epoch 2/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.2278 - binary_accuracy: 0.9308 - val_loss: 0.1487 - val_binary_accuracy: 0.9502\n",
      "Epoch 3/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.1362 - binary_accuracy: 0.9534 - val_loss: 0.1163 - val_binary_accuracy: 0.9584\n",
      "Epoch 4/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.1108 - binary_accuracy: 0.9597 - val_loss: 0.0987 - val_binary_accuracy: 0.9616\n",
      "Epoch 5/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0969 - binary_accuracy: 0.9638 - val_loss: 0.0944 - val_binary_accuracy: 0.9638\n",
      "Epoch 6/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0889 - binary_accuracy: 0.9664 - val_loss: 0.0870 - val_binary_accuracy: 0.9665\n",
      "Epoch 7/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0844 - binary_accuracy: 0.9688 - val_loss: 0.0797 - val_binary_accuracy: 0.9682\n",
      "Epoch 8/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0795 - binary_accuracy: 0.9709 - val_loss: 0.0780 - val_binary_accuracy: 0.9698\n",
      "Epoch 9/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0776 - binary_accuracy: 0.9710 - val_loss: 0.0751 - val_binary_accuracy: 0.9700\n",
      "Epoch 10/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0744 - binary_accuracy: 0.9718 - val_loss: 0.0711 - val_binary_accuracy: 0.9720\n",
      "Epoch 11/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0713 - binary_accuracy: 0.9727 - val_loss: 0.0711 - val_binary_accuracy: 0.9716\n",
      "Epoch 12/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0709 - binary_accuracy: 0.9727 - val_loss: 0.0701 - val_binary_accuracy: 0.9738\n",
      "Epoch 13/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0684 - binary_accuracy: 0.9737 - val_loss: 0.0667 - val_binary_accuracy: 0.9738\n",
      "Epoch 14/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0655 - binary_accuracy: 0.9755 - val_loss: 0.0657 - val_binary_accuracy: 0.9739\n",
      "Epoch 15/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0640 - binary_accuracy: 0.9756 - val_loss: 0.0644 - val_binary_accuracy: 0.9741\n",
      "Epoch 16/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0624 - binary_accuracy: 0.9763 - val_loss: 0.0626 - val_binary_accuracy: 0.9748\n",
      "Epoch 17/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0613 - binary_accuracy: 0.9766 - val_loss: 0.0649 - val_binary_accuracy: 0.9754\n",
      "Epoch 18/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0609 - binary_accuracy: 0.9765 - val_loss: 0.0599 - val_binary_accuracy: 0.9759\n",
      "Epoch 19/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0610 - binary_accuracy: 0.9761 - val_loss: 0.0609 - val_binary_accuracy: 0.9759\n",
      "Epoch 20/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0620 - binary_accuracy: 0.9773 - val_loss: 0.0598 - val_binary_accuracy: 0.9761\n",
      "Epoch 21/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0598 - binary_accuracy: 0.9774 - val_loss: 0.0585 - val_binary_accuracy: 0.9754\n",
      "Epoch 22/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0561 - binary_accuracy: 0.9784 - val_loss: 0.0597 - val_binary_accuracy: 0.9758\n",
      "Epoch 23/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0566 - binary_accuracy: 0.9780 - val_loss: 0.0568 - val_binary_accuracy: 0.9781\n",
      "Epoch 24/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0549 - binary_accuracy: 0.9788 - val_loss: 0.0556 - val_binary_accuracy: 0.9786\n",
      "Epoch 25/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0542 - binary_accuracy: 0.9788 - val_loss: 0.0584 - val_binary_accuracy: 0.9752\n",
      "Epoch 26/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0543 - binary_accuracy: 0.9791 - val_loss: 0.0579 - val_binary_accuracy: 0.9761\n",
      "Epoch 27/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0525 - binary_accuracy: 0.9788 - val_loss: 0.0623 - val_binary_accuracy: 0.9758\n",
      "Epoch 28/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0547 - binary_accuracy: 0.9786 - val_loss: 0.0656 - val_binary_accuracy: 0.9750\n",
      "Epoch 29/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0548 - binary_accuracy: 0.9800 - val_loss: 0.0557 - val_binary_accuracy: 0.9768\n",
      "Epoch 30/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0514 - binary_accuracy: 0.9798 - val_loss: 0.0523 - val_binary_accuracy: 0.9796\n",
      "Epoch 31/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0507 - binary_accuracy: 0.9809 - val_loss: 0.0535 - val_binary_accuracy: 0.9774\n",
      "Epoch 32/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0496 - binary_accuracy: 0.9809 - val_loss: 0.0524 - val_binary_accuracy: 0.9785\n",
      "Epoch 33/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0508 - binary_accuracy: 0.9812 - val_loss: 0.0563 - val_binary_accuracy: 0.9774\n",
      "Epoch 34/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0513 - binary_accuracy: 0.9806 - val_loss: 0.0632 - val_binary_accuracy: 0.9750\n",
      "Epoch 35/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0491 - binary_accuracy: 0.9815 - val_loss: 0.0513 - val_binary_accuracy: 0.9794\n",
      "Epoch 36/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0461 - binary_accuracy: 0.9824 - val_loss: 0.0502 - val_binary_accuracy: 0.9785\n",
      "Epoch 37/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0466 - binary_accuracy: 0.9830 - val_loss: 0.0515 - val_binary_accuracy: 0.9794\n",
      "Epoch 38/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0483 - binary_accuracy: 0.9826 - val_loss: 0.0517 - val_binary_accuracy: 0.9786\n",
      "Epoch 39/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0463 - binary_accuracy: 0.9827 - val_loss: 0.0520 - val_binary_accuracy: 0.9783\n",
      "Epoch 40/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0447 - binary_accuracy: 0.9842 - val_loss: 0.0553 - val_binary_accuracy: 0.9777\n",
      "Epoch 41/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0453 - binary_accuracy: 0.9830 - val_loss: 0.0486 - val_binary_accuracy: 0.9806\n",
      "Epoch 42/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0448 - binary_accuracy: 0.9844 - val_loss: 0.0472 - val_binary_accuracy: 0.9805\n",
      "Epoch 43/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0434 - binary_accuracy: 0.9846 - val_loss: 0.0465 - val_binary_accuracy: 0.9830\n",
      "Epoch 44/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0419 - binary_accuracy: 0.9850 - val_loss: 0.0477 - val_binary_accuracy: 0.9823\n",
      "Epoch 45/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0417 - binary_accuracy: 0.9850 - val_loss: 0.0479 - val_binary_accuracy: 0.9832\n",
      "Epoch 46/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0407 - binary_accuracy: 0.9853 - val_loss: 0.0498 - val_binary_accuracy: 0.9808\n",
      "Epoch 47/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0408 - binary_accuracy: 0.9865 - val_loss: 0.0477 - val_binary_accuracy: 0.9823\n",
      "Epoch 48/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0403 - binary_accuracy: 0.9859 - val_loss: 0.0471 - val_binary_accuracy: 0.9832\n",
      "Epoch 49/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0415 - binary_accuracy: 0.9852 - val_loss: 0.0452 - val_binary_accuracy: 0.9826\n",
      "Epoch 50/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0397 - binary_accuracy: 0.9862 - val_loss: 0.0450 - val_binary_accuracy: 0.9839\n",
      "Epoch 51/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0401 - binary_accuracy: 0.9864 - val_loss: 0.0499 - val_binary_accuracy: 0.9814\n",
      "Epoch 52/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0415 - binary_accuracy: 0.9854 - val_loss: 0.0487 - val_binary_accuracy: 0.9824\n",
      "Epoch 53/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0409 - binary_accuracy: 0.9858 - val_loss: 0.0453 - val_binary_accuracy: 0.9839\n",
      "Epoch 54/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0378 - binary_accuracy: 0.9874 - val_loss: 0.0453 - val_binary_accuracy: 0.9834\n",
      "Epoch 55/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0370 - binary_accuracy: 0.9873 - val_loss: 0.0448 - val_binary_accuracy: 0.9823\n",
      "Epoch 56/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0359 - binary_accuracy: 0.9883 - val_loss: 0.0439 - val_binary_accuracy: 0.9823\n",
      "Epoch 57/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0358 - binary_accuracy: 0.9883 - val_loss: 0.0447 - val_binary_accuracy: 0.9835\n",
      "Epoch 58/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0363 - binary_accuracy: 0.9880 - val_loss: 0.0506 - val_binary_accuracy: 0.9808\n",
      "Epoch 59/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0394 - binary_accuracy: 0.9860 - val_loss: 0.0454 - val_binary_accuracy: 0.9848\n",
      "Epoch 60/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0372 - binary_accuracy: 0.9870 - val_loss: 0.0435 - val_binary_accuracy: 0.9837\n",
      "Epoch 61/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0383 - binary_accuracy: 0.9872 - val_loss: 0.0422 - val_binary_accuracy: 0.9844\n",
      "Epoch 62/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0368 - binary_accuracy: 0.9880 - val_loss: 0.0435 - val_binary_accuracy: 0.9841\n",
      "Epoch 63/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0347 - binary_accuracy: 0.9886 - val_loss: 0.0440 - val_binary_accuracy: 0.9844\n",
      "Epoch 64/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0364 - binary_accuracy: 0.9883 - val_loss: 0.0434 - val_binary_accuracy: 0.9835\n",
      "Epoch 65/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0345 - binary_accuracy: 0.9888 - val_loss: 0.0442 - val_binary_accuracy: 0.9835\n",
      "Epoch 66/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0368 - binary_accuracy: 0.9870 - val_loss: 0.0503 - val_binary_accuracy: 0.9808\n",
      "Epoch 67/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0353 - binary_accuracy: 0.9882 - val_loss: 0.0430 - val_binary_accuracy: 0.9837\n",
      "Epoch 68/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0346 - binary_accuracy: 0.9888 - val_loss: 0.0453 - val_binary_accuracy: 0.9828\n",
      "Epoch 69/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0336 - binary_accuracy: 0.9893 - val_loss: 0.0429 - val_binary_accuracy: 0.9844\n",
      "Epoch 70/500\n",
      "29/29 [==============================] - 0s 5ms/step - loss: 0.0338 - binary_accuracy: 0.9890 - val_loss: 0.0462 - val_binary_accuracy: 0.9828\n",
      "Epoch 71/500\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.0341 - binary_accuracy: 0.9885 - val_loss: 0.0448 - val_binary_accuracy: 0.9841\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "#Pretraining using pseudo labels\n",
    "psuedo_label_model = DeepLearningModel(x_train, z_train,last_layer_activation='sigmoid',loss_fn='binary_crossentropy')\n",
    "# Define early stopping callback to monitor validation loss and stop if it doesn't improve for 5 epochs\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with 20 epochs and batch size of 32, using the early stopping callback\n",
    "history = psuedo_label_model.fit(x_train, z_train, epochs=500, batch_size=128, validation_data=(x_test, z_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "29/29 [==============================] - 2s 21ms/step - loss: 1.2615 - conv1d_transpose_1_loss: 0.6956 - conv1d_transpose_3_loss: 0.5659 - val_loss: 0.7587 - val_conv1d_transpose_1_loss: 0.3527 - val_conv1d_transpose_3_loss: 0.4059\n",
      "Epoch 2/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.6121 - conv1d_transpose_1_loss: 0.2243 - conv1d_transpose_3_loss: 0.3878 - val_loss: 0.5149 - val_conv1d_transpose_1_loss: 0.1429 - val_conv1d_transpose_3_loss: 0.3720\n",
      "Epoch 3/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4948 - conv1d_transpose_1_loss: 0.1315 - conv1d_transpose_3_loss: 0.3633 - val_loss: 0.4687 - val_conv1d_transpose_1_loss: 0.1144 - val_conv1d_transpose_3_loss: 0.3543\n",
      "Epoch 4/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4586 - conv1d_transpose_1_loss: 0.1098 - conv1d_transpose_3_loss: 0.3487 - val_loss: 0.4419 - val_conv1d_transpose_1_loss: 0.0989 - val_conv1d_transpose_3_loss: 0.3430\n",
      "Epoch 5/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.4365 - conv1d_transpose_1_loss: 0.0970 - conv1d_transpose_3_loss: 0.3395 - val_loss: 0.4267 - val_conv1d_transpose_1_loss: 0.0904 - val_conv1d_transpose_3_loss: 0.3363\n",
      "Epoch 6/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.4217 - conv1d_transpose_1_loss: 0.0877 - conv1d_transpose_3_loss: 0.3340 - val_loss: 0.4145 - val_conv1d_transpose_1_loss: 0.0829 - val_conv1d_transpose_3_loss: 0.3316\n",
      "Epoch 7/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.4103 - conv1d_transpose_1_loss: 0.0804 - conv1d_transpose_3_loss: 0.3299 - val_loss: 0.4051 - val_conv1d_transpose_1_loss: 0.0768 - val_conv1d_transpose_3_loss: 0.3283\n",
      "Epoch 8/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.4003 - conv1d_transpose_1_loss: 0.0737 - conv1d_transpose_3_loss: 0.3266 - val_loss: 0.3966 - val_conv1d_transpose_1_loss: 0.0715 - val_conv1d_transpose_3_loss: 0.3251\n",
      "Epoch 9/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3920 - conv1d_transpose_1_loss: 0.0681 - conv1d_transpose_3_loss: 0.3239 - val_loss: 0.3890 - val_conv1d_transpose_1_loss: 0.0666 - val_conv1d_transpose_3_loss: 0.3224\n",
      "Epoch 10/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3844 - conv1d_transpose_1_loss: 0.0631 - conv1d_transpose_3_loss: 0.3213 - val_loss: 0.3838 - val_conv1d_transpose_1_loss: 0.0635 - val_conv1d_transpose_3_loss: 0.3203\n",
      "Epoch 11/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3784 - conv1d_transpose_1_loss: 0.0595 - conv1d_transpose_3_loss: 0.3190 - val_loss: 0.3793 - val_conv1d_transpose_1_loss: 0.0611 - val_conv1d_transpose_3_loss: 0.3182\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3728 - conv1d_transpose_1_loss: 0.0559 - conv1d_transpose_3_loss: 0.3169 - val_loss: 0.3739 - val_conv1d_transpose_1_loss: 0.0576 - val_conv1d_transpose_3_loss: 0.3164\n",
      "Epoch 13/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3680 - conv1d_transpose_1_loss: 0.0530 - conv1d_transpose_3_loss: 0.3150 - val_loss: 0.3687 - val_conv1d_transpose_1_loss: 0.0547 - val_conv1d_transpose_3_loss: 0.3141\n",
      "Epoch 14/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3634 - conv1d_transpose_1_loss: 0.0507 - conv1d_transpose_3_loss: 0.3127 - val_loss: 0.3654 - val_conv1d_transpose_1_loss: 0.0533 - val_conv1d_transpose_3_loss: 0.3120\n",
      "Epoch 15/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3585 - conv1d_transpose_1_loss: 0.0481 - conv1d_transpose_3_loss: 0.3104 - val_loss: 0.3599 - val_conv1d_transpose_1_loss: 0.0497 - val_conv1d_transpose_3_loss: 0.3102\n",
      "Epoch 16/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3549 - conv1d_transpose_1_loss: 0.0466 - conv1d_transpose_3_loss: 0.3083 - val_loss: 0.3563 - val_conv1d_transpose_1_loss: 0.0486 - val_conv1d_transpose_3_loss: 0.3077\n",
      "Epoch 17/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3504 - conv1d_transpose_1_loss: 0.0446 - conv1d_transpose_3_loss: 0.3058 - val_loss: 0.3531 - val_conv1d_transpose_1_loss: 0.0479 - val_conv1d_transpose_3_loss: 0.3052\n",
      "Epoch 18/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3470 - conv1d_transpose_1_loss: 0.0436 - conv1d_transpose_3_loss: 0.3034 - val_loss: 0.3493 - val_conv1d_transpose_1_loss: 0.0465 - val_conv1d_transpose_3_loss: 0.3028\n",
      "Epoch 19/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3429 - conv1d_transpose_1_loss: 0.0423 - conv1d_transpose_3_loss: 0.3006 - val_loss: 0.3457 - val_conv1d_transpose_1_loss: 0.0453 - val_conv1d_transpose_3_loss: 0.3004\n",
      "Epoch 20/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3385 - conv1d_transpose_1_loss: 0.0408 - conv1d_transpose_3_loss: 0.2977 - val_loss: 0.3411 - val_conv1d_transpose_1_loss: 0.0440 - val_conv1d_transpose_3_loss: 0.2971\n",
      "Epoch 21/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3342 - conv1d_transpose_1_loss: 0.0397 - conv1d_transpose_3_loss: 0.2946 - val_loss: 0.3370 - val_conv1d_transpose_1_loss: 0.0430 - val_conv1d_transpose_3_loss: 0.2940\n",
      "Epoch 22/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3300 - conv1d_transpose_1_loss: 0.0389 - conv1d_transpose_3_loss: 0.2911 - val_loss: 0.3322 - val_conv1d_transpose_1_loss: 0.0416 - val_conv1d_transpose_3_loss: 0.2905\n",
      "Epoch 23/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3255 - conv1d_transpose_1_loss: 0.0377 - conv1d_transpose_3_loss: 0.2878 - val_loss: 0.3287 - val_conv1d_transpose_1_loss: 0.0417 - val_conv1d_transpose_3_loss: 0.2871\n",
      "Epoch 24/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3216 - conv1d_transpose_1_loss: 0.0379 - conv1d_transpose_3_loss: 0.2837 - val_loss: 0.3239 - val_conv1d_transpose_1_loss: 0.0409 - val_conv1d_transpose_3_loss: 0.2830\n",
      "Epoch 25/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3164 - conv1d_transpose_1_loss: 0.0370 - conv1d_transpose_3_loss: 0.2795 - val_loss: 0.3193 - val_conv1d_transpose_1_loss: 0.0403 - val_conv1d_transpose_3_loss: 0.2789\n",
      "Epoch 26/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3115 - conv1d_transpose_1_loss: 0.0365 - conv1d_transpose_3_loss: 0.2750 - val_loss: 0.3139 - val_conv1d_transpose_1_loss: 0.0397 - val_conv1d_transpose_3_loss: 0.2742\n",
      "Epoch 27/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.3065 - conv1d_transpose_1_loss: 0.0363 - conv1d_transpose_3_loss: 0.2701 - val_loss: 0.3089 - val_conv1d_transpose_1_loss: 0.0395 - val_conv1d_transpose_3_loss: 0.2694\n",
      "Epoch 28/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.3011 - conv1d_transpose_1_loss: 0.0358 - conv1d_transpose_3_loss: 0.2653 - val_loss: 0.3040 - val_conv1d_transpose_1_loss: 0.0395 - val_conv1d_transpose_3_loss: 0.2645\n",
      "Epoch 29/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2962 - conv1d_transpose_1_loss: 0.0360 - conv1d_transpose_3_loss: 0.2602 - val_loss: 0.3004 - val_conv1d_transpose_1_loss: 0.0398 - val_conv1d_transpose_3_loss: 0.2606\n",
      "Epoch 30/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2909 - conv1d_transpose_1_loss: 0.0355 - conv1d_transpose_3_loss: 0.2555 - val_loss: 0.2942 - val_conv1d_transpose_1_loss: 0.0388 - val_conv1d_transpose_3_loss: 0.2554\n",
      "Epoch 31/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2859 - conv1d_transpose_1_loss: 0.0351 - conv1d_transpose_3_loss: 0.2508 - val_loss: 0.2896 - val_conv1d_transpose_1_loss: 0.0385 - val_conv1d_transpose_3_loss: 0.2511\n",
      "Epoch 32/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2814 - conv1d_transpose_1_loss: 0.0347 - conv1d_transpose_3_loss: 0.2467 - val_loss: 0.2851 - val_conv1d_transpose_1_loss: 0.0378 - val_conv1d_transpose_3_loss: 0.2473\n",
      "Epoch 33/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2772 - conv1d_transpose_1_loss: 0.0347 - conv1d_transpose_3_loss: 0.2426 - val_loss: 0.2817 - val_conv1d_transpose_1_loss: 0.0382 - val_conv1d_transpose_3_loss: 0.2435\n",
      "Epoch 34/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2732 - conv1d_transpose_1_loss: 0.0343 - conv1d_transpose_3_loss: 0.2389 - val_loss: 0.2780 - val_conv1d_transpose_1_loss: 0.0383 - val_conv1d_transpose_3_loss: 0.2396\n",
      "Epoch 35/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2689 - conv1d_transpose_1_loss: 0.0336 - conv1d_transpose_3_loss: 0.2353 - val_loss: 0.2735 - val_conv1d_transpose_1_loss: 0.0369 - val_conv1d_transpose_3_loss: 0.2366\n",
      "Epoch 36/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2660 - conv1d_transpose_1_loss: 0.0339 - conv1d_transpose_3_loss: 0.2321 - val_loss: 0.2709 - val_conv1d_transpose_1_loss: 0.0373 - val_conv1d_transpose_3_loss: 0.2336\n",
      "Epoch 37/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2624 - conv1d_transpose_1_loss: 0.0334 - conv1d_transpose_3_loss: 0.2290 - val_loss: 0.2681 - val_conv1d_transpose_1_loss: 0.0365 - val_conv1d_transpose_3_loss: 0.2316\n",
      "Epoch 38/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2592 - conv1d_transpose_1_loss: 0.0328 - conv1d_transpose_3_loss: 0.2264 - val_loss: 0.2655 - val_conv1d_transpose_1_loss: 0.0369 - val_conv1d_transpose_3_loss: 0.2286\n",
      "Epoch 39/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2559 - conv1d_transpose_1_loss: 0.0324 - conv1d_transpose_3_loss: 0.2235 - val_loss: 0.2622 - val_conv1d_transpose_1_loss: 0.0361 - val_conv1d_transpose_3_loss: 0.2261\n",
      "Epoch 40/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2540 - conv1d_transpose_1_loss: 0.0325 - conv1d_transpose_3_loss: 0.2215 - val_loss: 0.2598 - val_conv1d_transpose_1_loss: 0.0358 - val_conv1d_transpose_3_loss: 0.2241\n",
      "Epoch 41/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2506 - conv1d_transpose_1_loss: 0.0316 - conv1d_transpose_3_loss: 0.2190 - val_loss: 0.2572 - val_conv1d_transpose_1_loss: 0.0353 - val_conv1d_transpose_3_loss: 0.2219\n",
      "Epoch 42/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2482 - conv1d_transpose_1_loss: 0.0313 - conv1d_transpose_3_loss: 0.2168 - val_loss: 0.2550 - val_conv1d_transpose_1_loss: 0.0348 - val_conv1d_transpose_3_loss: 0.2202\n",
      "Epoch 43/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2459 - conv1d_transpose_1_loss: 0.0310 - conv1d_transpose_3_loss: 0.2149 - val_loss: 0.2536 - val_conv1d_transpose_1_loss: 0.0352 - val_conv1d_transpose_3_loss: 0.2184\n",
      "Epoch 44/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2434 - conv1d_transpose_1_loss: 0.0306 - conv1d_transpose_3_loss: 0.2128 - val_loss: 0.2510 - val_conv1d_transpose_1_loss: 0.0343 - val_conv1d_transpose_3_loss: 0.2167\n",
      "Epoch 45/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2419 - conv1d_transpose_1_loss: 0.0308 - conv1d_transpose_3_loss: 0.2111 - val_loss: 0.2505 - val_conv1d_transpose_1_loss: 0.0351 - val_conv1d_transpose_3_loss: 0.2154\n",
      "Epoch 46/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2396 - conv1d_transpose_1_loss: 0.0302 - conv1d_transpose_3_loss: 0.2095 - val_loss: 0.2478 - val_conv1d_transpose_1_loss: 0.0338 - val_conv1d_transpose_3_loss: 0.2141\n",
      "Epoch 47/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2380 - conv1d_transpose_1_loss: 0.0299 - conv1d_transpose_3_loss: 0.2081 - val_loss: 0.2465 - val_conv1d_transpose_1_loss: 0.0336 - val_conv1d_transpose_3_loss: 0.2129\n",
      "Epoch 48/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2366 - conv1d_transpose_1_loss: 0.0298 - conv1d_transpose_3_loss: 0.2068 - val_loss: 0.2446 - val_conv1d_transpose_1_loss: 0.0331 - val_conv1d_transpose_3_loss: 0.2115\n",
      "Epoch 49/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2349 - conv1d_transpose_1_loss: 0.0296 - conv1d_transpose_3_loss: 0.2053 - val_loss: 0.2437 - val_conv1d_transpose_1_loss: 0.0332 - val_conv1d_transpose_3_loss: 0.2105\n",
      "Epoch 50/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2336 - conv1d_transpose_1_loss: 0.0295 - conv1d_transpose_3_loss: 0.2041 - val_loss: 0.2423 - val_conv1d_transpose_1_loss: 0.0330 - val_conv1d_transpose_3_loss: 0.2093\n",
      "Epoch 51/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2320 - conv1d_transpose_1_loss: 0.0290 - conv1d_transpose_3_loss: 0.2029 - val_loss: 0.2413 - val_conv1d_transpose_1_loss: 0.0329 - val_conv1d_transpose_3_loss: 0.2084\n",
      "Epoch 52/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2306 - conv1d_transpose_1_loss: 0.0289 - conv1d_transpose_3_loss: 0.2017 - val_loss: 0.2396 - val_conv1d_transpose_1_loss: 0.0322 - val_conv1d_transpose_3_loss: 0.2074\n",
      "Epoch 53/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2292 - conv1d_transpose_1_loss: 0.0286 - conv1d_transpose_3_loss: 0.2006 - val_loss: 0.2384 - val_conv1d_transpose_1_loss: 0.0324 - val_conv1d_transpose_3_loss: 0.2060\n",
      "Epoch 54/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2283 - conv1d_transpose_1_loss: 0.0287 - conv1d_transpose_3_loss: 0.1995 - val_loss: 0.2373 - val_conv1d_transpose_1_loss: 0.0320 - val_conv1d_transpose_3_loss: 0.2053\n",
      "Epoch 55/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2271 - conv1d_transpose_1_loss: 0.0285 - conv1d_transpose_3_loss: 0.1987 - val_loss: 0.2370 - val_conv1d_transpose_1_loss: 0.0320 - val_conv1d_transpose_3_loss: 0.2050\n",
      "Epoch 56/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2264 - conv1d_transpose_1_loss: 0.0286 - conv1d_transpose_3_loss: 0.1978 - val_loss: 0.2362 - val_conv1d_transpose_1_loss: 0.0321 - val_conv1d_transpose_3_loss: 0.2041\n",
      "Epoch 57/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2251 - conv1d_transpose_1_loss: 0.0281 - conv1d_transpose_3_loss: 0.1970 - val_loss: 0.2345 - val_conv1d_transpose_1_loss: 0.0314 - val_conv1d_transpose_3_loss: 0.2031\n",
      "Epoch 58/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2235 - conv1d_transpose_1_loss: 0.0276 - conv1d_transpose_3_loss: 0.1959 - val_loss: 0.2334 - val_conv1d_transpose_1_loss: 0.0314 - val_conv1d_transpose_3_loss: 0.2020\n",
      "Epoch 59/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2229 - conv1d_transpose_1_loss: 0.0278 - conv1d_transpose_3_loss: 0.1950 - val_loss: 0.2327 - val_conv1d_transpose_1_loss: 0.0313 - val_conv1d_transpose_3_loss: 0.2015\n",
      "Epoch 60/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2216 - conv1d_transpose_1_loss: 0.0275 - conv1d_transpose_3_loss: 0.1941 - val_loss: 0.2327 - val_conv1d_transpose_1_loss: 0.0315 - val_conv1d_transpose_3_loss: 0.2012\n",
      "Epoch 61/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2210 - conv1d_transpose_1_loss: 0.0275 - conv1d_transpose_3_loss: 0.1935 - val_loss: 0.2308 - val_conv1d_transpose_1_loss: 0.0307 - val_conv1d_transpose_3_loss: 0.2001\n",
      "Epoch 62/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2197 - conv1d_transpose_1_loss: 0.0272 - conv1d_transpose_3_loss: 0.1925 - val_loss: 0.2306 - val_conv1d_transpose_1_loss: 0.0316 - val_conv1d_transpose_3_loss: 0.1990\n",
      "Epoch 63/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2193 - conv1d_transpose_1_loss: 0.0275 - conv1d_transpose_3_loss: 0.1918 - val_loss: 0.2288 - val_conv1d_transpose_1_loss: 0.0302 - val_conv1d_transpose_3_loss: 0.1986\n",
      "Epoch 64/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2183 - conv1d_transpose_1_loss: 0.0272 - conv1d_transpose_3_loss: 0.1911 - val_loss: 0.2281 - val_conv1d_transpose_1_loss: 0.0302 - val_conv1d_transpose_3_loss: 0.1979\n",
      "Epoch 65/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2171 - conv1d_transpose_1_loss: 0.0266 - conv1d_transpose_3_loss: 0.1904 - val_loss: 0.2274 - val_conv1d_transpose_1_loss: 0.0301 - val_conv1d_transpose_3_loss: 0.1972\n",
      "Epoch 66/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2161 - conv1d_transpose_1_loss: 0.0264 - conv1d_transpose_3_loss: 0.1897 - val_loss: 0.2273 - val_conv1d_transpose_1_loss: 0.0301 - val_conv1d_transpose_3_loss: 0.1972\n",
      "Epoch 67/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2156 - conv1d_transpose_1_loss: 0.0266 - conv1d_transpose_3_loss: 0.1891 - val_loss: 0.2255 - val_conv1d_transpose_1_loss: 0.0295 - val_conv1d_transpose_3_loss: 0.1960\n",
      "Epoch 68/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2148 - conv1d_transpose_1_loss: 0.0263 - conv1d_transpose_3_loss: 0.1885 - val_loss: 0.2252 - val_conv1d_transpose_1_loss: 0.0295 - val_conv1d_transpose_3_loss: 0.1957\n",
      "Epoch 69/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2136 - conv1d_transpose_1_loss: 0.0260 - conv1d_transpose_3_loss: 0.1876 - val_loss: 0.2239 - val_conv1d_transpose_1_loss: 0.0295 - val_conv1d_transpose_3_loss: 0.1944\n",
      "Epoch 70/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2128 - conv1d_transpose_1_loss: 0.0260 - conv1d_transpose_3_loss: 0.1868 - val_loss: 0.2228 - val_conv1d_transpose_1_loss: 0.0291 - val_conv1d_transpose_3_loss: 0.1938\n",
      "Epoch 71/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2125 - conv1d_transpose_1_loss: 0.0260 - conv1d_transpose_3_loss: 0.1865 - val_loss: 0.2226 - val_conv1d_transpose_1_loss: 0.0296 - val_conv1d_transpose_3_loss: 0.1930\n",
      "Epoch 72/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2113 - conv1d_transpose_1_loss: 0.0259 - conv1d_transpose_3_loss: 0.1854 - val_loss: 0.2221 - val_conv1d_transpose_1_loss: 0.0294 - val_conv1d_transpose_3_loss: 0.1927\n",
      "Epoch 73/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2107 - conv1d_transpose_1_loss: 0.0258 - conv1d_transpose_3_loss: 0.1849 - val_loss: 0.2221 - val_conv1d_transpose_1_loss: 0.0293 - val_conv1d_transpose_3_loss: 0.1927\n",
      "Epoch 74/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2095 - conv1d_transpose_1_loss: 0.0254 - conv1d_transpose_3_loss: 0.1841 - val_loss: 0.2199 - val_conv1d_transpose_1_loss: 0.0288 - val_conv1d_transpose_3_loss: 0.1912\n",
      "Epoch 75/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2089 - conv1d_transpose_1_loss: 0.0253 - conv1d_transpose_3_loss: 0.1836 - val_loss: 0.2191 - val_conv1d_transpose_1_loss: 0.0286 - val_conv1d_transpose_3_loss: 0.1905\n",
      "Epoch 76/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2079 - conv1d_transpose_1_loss: 0.0252 - conv1d_transpose_3_loss: 0.1827 - val_loss: 0.2188 - val_conv1d_transpose_1_loss: 0.0285 - val_conv1d_transpose_3_loss: 0.1903\n",
      "Epoch 77/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2079 - conv1d_transpose_1_loss: 0.0256 - conv1d_transpose_3_loss: 0.1823 - val_loss: 0.2186 - val_conv1d_transpose_1_loss: 0.0284 - val_conv1d_transpose_3_loss: 0.1901\n",
      "Epoch 78/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2063 - conv1d_transpose_1_loss: 0.0249 - conv1d_transpose_3_loss: 0.1814 - val_loss: 0.2172 - val_conv1d_transpose_1_loss: 0.0284 - val_conv1d_transpose_3_loss: 0.1888\n",
      "Epoch 79/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2053 - conv1d_transpose_1_loss: 0.0248 - conv1d_transpose_3_loss: 0.1805 - val_loss: 0.2163 - val_conv1d_transpose_1_loss: 0.0283 - val_conv1d_transpose_3_loss: 0.1880\n",
      "Epoch 80/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2045 - conv1d_transpose_1_loss: 0.0246 - conv1d_transpose_3_loss: 0.1798 - val_loss: 0.2151 - val_conv1d_transpose_1_loss: 0.0278 - val_conv1d_transpose_3_loss: 0.1872\n",
      "Epoch 81/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2036 - conv1d_transpose_1_loss: 0.0246 - conv1d_transpose_3_loss: 0.1789 - val_loss: 0.2142 - val_conv1d_transpose_1_loss: 0.0281 - val_conv1d_transpose_3_loss: 0.1861\n",
      "Epoch 82/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2029 - conv1d_transpose_1_loss: 0.0249 - conv1d_transpose_3_loss: 0.1781 - val_loss: 0.2139 - val_conv1d_transpose_1_loss: 0.0284 - val_conv1d_transpose_3_loss: 0.1855\n",
      "Epoch 83/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2019 - conv1d_transpose_1_loss: 0.0249 - conv1d_transpose_3_loss: 0.1770 - val_loss: 0.2120 - val_conv1d_transpose_1_loss: 0.0276 - val_conv1d_transpose_3_loss: 0.1844\n",
      "Epoch 84/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.2009 - conv1d_transpose_1_loss: 0.0245 - conv1d_transpose_3_loss: 0.1764 - val_loss: 0.2126 - val_conv1d_transpose_1_loss: 0.0281 - val_conv1d_transpose_3_loss: 0.1845\n",
      "Epoch 85/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.2006 - conv1d_transpose_1_loss: 0.0249 - conv1d_transpose_3_loss: 0.1757 - val_loss: 0.2108 - val_conv1d_transpose_1_loss: 0.0278 - val_conv1d_transpose_3_loss: 0.1829\n",
      "Epoch 86/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1992 - conv1d_transpose_1_loss: 0.0244 - conv1d_transpose_3_loss: 0.1748 - val_loss: 0.2094 - val_conv1d_transpose_1_loss: 0.0275 - val_conv1d_transpose_3_loss: 0.1819\n",
      "Epoch 87/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1982 - conv1d_transpose_1_loss: 0.0246 - conv1d_transpose_3_loss: 0.1736 - val_loss: 0.2085 - val_conv1d_transpose_1_loss: 0.0274 - val_conv1d_transpose_3_loss: 0.1811\n",
      "Epoch 88/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1969 - conv1d_transpose_1_loss: 0.0241 - conv1d_transpose_3_loss: 0.1728 - val_loss: 0.2079 - val_conv1d_transpose_1_loss: 0.0274 - val_conv1d_transpose_3_loss: 0.1804\n",
      "Epoch 89/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1962 - conv1d_transpose_1_loss: 0.0243 - conv1d_transpose_3_loss: 0.1719 - val_loss: 0.2069 - val_conv1d_transpose_1_loss: 0.0277 - val_conv1d_transpose_3_loss: 0.1793\n",
      "Epoch 90/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1947 - conv1d_transpose_1_loss: 0.0242 - conv1d_transpose_3_loss: 0.1705 - val_loss: 0.2056 - val_conv1d_transpose_1_loss: 0.0270 - val_conv1d_transpose_3_loss: 0.1786\n",
      "Epoch 91/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1940 - conv1d_transpose_1_loss: 0.0242 - conv1d_transpose_3_loss: 0.1698 - val_loss: 0.2050 - val_conv1d_transpose_1_loss: 0.0278 - val_conv1d_transpose_3_loss: 0.1771\n",
      "Epoch 92/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1926 - conv1d_transpose_1_loss: 0.0242 - conv1d_transpose_3_loss: 0.1684 - val_loss: 0.2032 - val_conv1d_transpose_1_loss: 0.0271 - val_conv1d_transpose_3_loss: 0.1761\n",
      "Epoch 93/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1910 - conv1d_transpose_1_loss: 0.0238 - conv1d_transpose_3_loss: 0.1672 - val_loss: 0.2027 - val_conv1d_transpose_1_loss: 0.0273 - val_conv1d_transpose_3_loss: 0.1754\n",
      "Epoch 94/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1907 - conv1d_transpose_1_loss: 0.0238 - conv1d_transpose_3_loss: 0.1669 - val_loss: 0.2009 - val_conv1d_transpose_1_loss: 0.0269 - val_conv1d_transpose_3_loss: 0.1741\n",
      "Epoch 95/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1891 - conv1d_transpose_1_loss: 0.0240 - conv1d_transpose_3_loss: 0.1650 - val_loss: 0.2024 - val_conv1d_transpose_1_loss: 0.0291 - val_conv1d_transpose_3_loss: 0.1733\n",
      "Epoch 96/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1884 - conv1d_transpose_1_loss: 0.0243 - conv1d_transpose_3_loss: 0.1641 - val_loss: 0.1987 - val_conv1d_transpose_1_loss: 0.0271 - val_conv1d_transpose_3_loss: 0.1716\n",
      "Epoch 97/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1867 - conv1d_transpose_1_loss: 0.0237 - conv1d_transpose_3_loss: 0.1630 - val_loss: 0.1978 - val_conv1d_transpose_1_loss: 0.0269 - val_conv1d_transpose_3_loss: 0.1709\n",
      "Epoch 98/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1857 - conv1d_transpose_1_loss: 0.0238 - conv1d_transpose_3_loss: 0.1619 - val_loss: 0.1962 - val_conv1d_transpose_1_loss: 0.0263 - val_conv1d_transpose_3_loss: 0.1699\n",
      "Epoch 99/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1845 - conv1d_transpose_1_loss: 0.0238 - conv1d_transpose_3_loss: 0.1607 - val_loss: 0.1960 - val_conv1d_transpose_1_loss: 0.0273 - val_conv1d_transpose_3_loss: 0.1687\n",
      "Epoch 100/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1830 - conv1d_transpose_1_loss: 0.0238 - conv1d_transpose_3_loss: 0.1592 - val_loss: 0.1951 - val_conv1d_transpose_1_loss: 0.0274 - val_conv1d_transpose_3_loss: 0.1677\n",
      "Epoch 101/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1822 - conv1d_transpose_1_loss: 0.0237 - conv1d_transpose_3_loss: 0.1586 - val_loss: 0.1927 - val_conv1d_transpose_1_loss: 0.0260 - val_conv1d_transpose_3_loss: 0.1667\n",
      "Epoch 102/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1806 - conv1d_transpose_1_loss: 0.0232 - conv1d_transpose_3_loss: 0.1574 - val_loss: 0.1925 - val_conv1d_transpose_1_loss: 0.0265 - val_conv1d_transpose_3_loss: 0.1659\n",
      "Epoch 103/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1812 - conv1d_transpose_1_loss: 0.0245 - conv1d_transpose_3_loss: 0.1566 - val_loss: 0.1922 - val_conv1d_transpose_1_loss: 0.0274 - val_conv1d_transpose_3_loss: 0.1649\n",
      "Epoch 104/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1791 - conv1d_transpose_1_loss: 0.0231 - conv1d_transpose_3_loss: 0.1561 - val_loss: 0.1906 - val_conv1d_transpose_1_loss: 0.0258 - val_conv1d_transpose_3_loss: 0.1648\n",
      "Epoch 105/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1785 - conv1d_transpose_1_loss: 0.0236 - conv1d_transpose_3_loss: 0.1549 - val_loss: 0.1891 - val_conv1d_transpose_1_loss: 0.0262 - val_conv1d_transpose_3_loss: 0.1629\n",
      "Epoch 106/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1769 - conv1d_transpose_1_loss: 0.0233 - conv1d_transpose_3_loss: 0.1537 - val_loss: 0.1902 - val_conv1d_transpose_1_loss: 0.0270 - val_conv1d_transpose_3_loss: 0.1632\n",
      "Epoch 107/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1765 - conv1d_transpose_1_loss: 0.0235 - conv1d_transpose_3_loss: 0.1531 - val_loss: 0.1878 - val_conv1d_transpose_1_loss: 0.0256 - val_conv1d_transpose_3_loss: 0.1622\n",
      "Epoch 108/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1750 - conv1d_transpose_1_loss: 0.0229 - conv1d_transpose_3_loss: 0.1521 - val_loss: 0.1873 - val_conv1d_transpose_1_loss: 0.0257 - val_conv1d_transpose_3_loss: 0.1616\n",
      "Epoch 109/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1743 - conv1d_transpose_1_loss: 0.0227 - conv1d_transpose_3_loss: 0.1516 - val_loss: 0.1883 - val_conv1d_transpose_1_loss: 0.0263 - val_conv1d_transpose_3_loss: 0.1619\n",
      "Epoch 110/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1736 - conv1d_transpose_1_loss: 0.0227 - conv1d_transpose_3_loss: 0.1509 - val_loss: 0.1864 - val_conv1d_transpose_1_loss: 0.0255 - val_conv1d_transpose_3_loss: 0.1610\n",
      "Epoch 111/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1731 - conv1d_transpose_1_loss: 0.0229 - conv1d_transpose_3_loss: 0.1501 - val_loss: 0.1838 - val_conv1d_transpose_1_loss: 0.0255 - val_conv1d_transpose_3_loss: 0.1582\n",
      "Epoch 112/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1721 - conv1d_transpose_1_loss: 0.0225 - conv1d_transpose_3_loss: 0.1496 - val_loss: 0.1828 - val_conv1d_transpose_1_loss: 0.0248 - val_conv1d_transpose_3_loss: 0.1580\n",
      "Epoch 113/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1718 - conv1d_transpose_1_loss: 0.0226 - conv1d_transpose_3_loss: 0.1492 - val_loss: 0.1837 - val_conv1d_transpose_1_loss: 0.0253 - val_conv1d_transpose_3_loss: 0.1584\n",
      "Epoch 114/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1707 - conv1d_transpose_1_loss: 0.0225 - conv1d_transpose_3_loss: 0.1482 - val_loss: 0.1838 - val_conv1d_transpose_1_loss: 0.0269 - val_conv1d_transpose_3_loss: 0.1568\n",
      "Epoch 115/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1712 - conv1d_transpose_1_loss: 0.0234 - conv1d_transpose_3_loss: 0.1478 - val_loss: 0.1835 - val_conv1d_transpose_1_loss: 0.0257 - val_conv1d_transpose_3_loss: 0.1578\n",
      "Epoch 116/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1701 - conv1d_transpose_1_loss: 0.0228 - conv1d_transpose_3_loss: 0.1473 - val_loss: 0.1822 - val_conv1d_transpose_1_loss: 0.0266 - val_conv1d_transpose_3_loss: 0.1556\n",
      "Epoch 117/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1684 - conv1d_transpose_1_loss: 0.0221 - conv1d_transpose_3_loss: 0.1463 - val_loss: 0.1802 - val_conv1d_transpose_1_loss: 0.0256 - val_conv1d_transpose_3_loss: 0.1546\n",
      "Epoch 118/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1680 - conv1d_transpose_1_loss: 0.0225 - conv1d_transpose_3_loss: 0.1455 - val_loss: 0.1815 - val_conv1d_transpose_1_loss: 0.0254 - val_conv1d_transpose_3_loss: 0.1561\n",
      "Epoch 119/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1689 - conv1d_transpose_1_loss: 0.0233 - conv1d_transpose_3_loss: 0.1456 - val_loss: 0.1801 - val_conv1d_transpose_1_loss: 0.0252 - val_conv1d_transpose_3_loss: 0.1549\n",
      "Epoch 120/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1669 - conv1d_transpose_1_loss: 0.0221 - conv1d_transpose_3_loss: 0.1447 - val_loss: 0.1814 - val_conv1d_transpose_1_loss: 0.0257 - val_conv1d_transpose_3_loss: 0.1557\n",
      "Epoch 121/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1669 - conv1d_transpose_1_loss: 0.0227 - conv1d_transpose_3_loss: 0.1442 - val_loss: 0.1807 - val_conv1d_transpose_1_loss: 0.0260 - val_conv1d_transpose_3_loss: 0.1547\n",
      "Epoch 122/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1669 - conv1d_transpose_1_loss: 0.0228 - conv1d_transpose_3_loss: 0.1441 - val_loss: 0.1785 - val_conv1d_transpose_1_loss: 0.0247 - val_conv1d_transpose_3_loss: 0.1537\n",
      "Epoch 123/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1664 - conv1d_transpose_1_loss: 0.0220 - conv1d_transpose_3_loss: 0.1444 - val_loss: 0.1804 - val_conv1d_transpose_1_loss: 0.0272 - val_conv1d_transpose_3_loss: 0.1532\n",
      "Epoch 124/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1661 - conv1d_transpose_1_loss: 0.0223 - conv1d_transpose_3_loss: 0.1438 - val_loss: 0.1778 - val_conv1d_transpose_1_loss: 0.0249 - val_conv1d_transpose_3_loss: 0.1529\n",
      "Epoch 125/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1643 - conv1d_transpose_1_loss: 0.0215 - conv1d_transpose_3_loss: 0.1428 - val_loss: 0.1768 - val_conv1d_transpose_1_loss: 0.0242 - val_conv1d_transpose_3_loss: 0.1527\n",
      "Epoch 126/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1638 - conv1d_transpose_1_loss: 0.0215 - conv1d_transpose_3_loss: 0.1423 - val_loss: 0.1760 - val_conv1d_transpose_1_loss: 0.0244 - val_conv1d_transpose_3_loss: 0.1516\n",
      "Epoch 127/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1646 - conv1d_transpose_1_loss: 0.0227 - conv1d_transpose_3_loss: 0.1419 - val_loss: 0.1770 - val_conv1d_transpose_1_loss: 0.0252 - val_conv1d_transpose_3_loss: 0.1519\n",
      "Epoch 128/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1635 - conv1d_transpose_1_loss: 0.0223 - conv1d_transpose_3_loss: 0.1412 - val_loss: 0.1764 - val_conv1d_transpose_1_loss: 0.0248 - val_conv1d_transpose_3_loss: 0.1516\n",
      "Epoch 129/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1623 - conv1d_transpose_1_loss: 0.0213 - conv1d_transpose_3_loss: 0.1410 - val_loss: 0.1751 - val_conv1d_transpose_1_loss: 0.0239 - val_conv1d_transpose_3_loss: 0.1512\n",
      "Epoch 130/200\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.1624 - conv1d_transpose_1_loss: 0.0214 - conv1d_transpose_3_loss: 0.1410 - val_loss: 0.1759 - val_conv1d_transpose_1_loss: 0.0246 - val_conv1d_transpose_3_loss: 0.1514\n",
      "Epoch 131/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1623 - conv1d_transpose_1_loss: 0.0215 - conv1d_transpose_3_loss: 0.1408 - val_loss: 0.1748 - val_conv1d_transpose_1_loss: 0.0241 - val_conv1d_transpose_3_loss: 0.1508\n",
      "Epoch 132/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1613 - conv1d_transpose_1_loss: 0.0211 - conv1d_transpose_3_loss: 0.1402 - val_loss: 0.1732 - val_conv1d_transpose_1_loss: 0.0236 - val_conv1d_transpose_3_loss: 0.1496\n",
      "Epoch 133/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1608 - conv1d_transpose_1_loss: 0.0208 - conv1d_transpose_3_loss: 0.1399 - val_loss: 0.1744 - val_conv1d_transpose_1_loss: 0.0245 - val_conv1d_transpose_3_loss: 0.1499\n",
      "Epoch 134/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1607 - conv1d_transpose_1_loss: 0.0211 - conv1d_transpose_3_loss: 0.1396 - val_loss: 0.1735 - val_conv1d_transpose_1_loss: 0.0238 - val_conv1d_transpose_3_loss: 0.1497\n",
      "Epoch 135/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1603 - conv1d_transpose_1_loss: 0.0212 - conv1d_transpose_3_loss: 0.1391 - val_loss: 0.1737 - val_conv1d_transpose_1_loss: 0.0249 - val_conv1d_transpose_3_loss: 0.1488\n",
      "Epoch 136/200\n",
      "29/29 [==============================] - 0s 8ms/step - loss: 0.1600 - conv1d_transpose_1_loss: 0.0216 - conv1d_transpose_3_loss: 0.1384 - val_loss: 0.1728 - val_conv1d_transpose_1_loss: 0.0239 - val_conv1d_transpose_3_loss: 0.1489\n",
      "Epoch 137/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1601 - conv1d_transpose_1_loss: 0.0216 - conv1d_transpose_3_loss: 0.1385 - val_loss: 0.1723 - val_conv1d_transpose_1_loss: 0.0239 - val_conv1d_transpose_3_loss: 0.1484\n",
      "Epoch 138/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1592 - conv1d_transpose_1_loss: 0.0213 - conv1d_transpose_3_loss: 0.1378 - val_loss: 0.1725 - val_conv1d_transpose_1_loss: 0.0241 - val_conv1d_transpose_3_loss: 0.1484\n",
      "Epoch 139/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1589 - conv1d_transpose_1_loss: 0.0211 - conv1d_transpose_3_loss: 0.1378 - val_loss: 0.1725 - val_conv1d_transpose_1_loss: 0.0235 - val_conv1d_transpose_3_loss: 0.1491\n",
      "Epoch 140/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1581 - conv1d_transpose_1_loss: 0.0204 - conv1d_transpose_3_loss: 0.1377 - val_loss: 0.1716 - val_conv1d_transpose_1_loss: 0.0243 - val_conv1d_transpose_3_loss: 0.1473\n",
      "Epoch 141/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1580 - conv1d_transpose_1_loss: 0.0211 - conv1d_transpose_3_loss: 0.1369 - val_loss: 0.1735 - val_conv1d_transpose_1_loss: 0.0248 - val_conv1d_transpose_3_loss: 0.1486\n",
      "Epoch 142/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1578 - conv1d_transpose_1_loss: 0.0208 - conv1d_transpose_3_loss: 0.1370 - val_loss: 0.1725 - val_conv1d_transpose_1_loss: 0.0238 - val_conv1d_transpose_3_loss: 0.1487\n",
      "Epoch 143/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1578 - conv1d_transpose_1_loss: 0.0209 - conv1d_transpose_3_loss: 0.1370 - val_loss: 0.1729 - val_conv1d_transpose_1_loss: 0.0243 - val_conv1d_transpose_3_loss: 0.1485\n",
      "Epoch 144/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1574 - conv1d_transpose_1_loss: 0.0207 - conv1d_transpose_3_loss: 0.1367 - val_loss: 0.1702 - val_conv1d_transpose_1_loss: 0.0232 - val_conv1d_transpose_3_loss: 0.1470\n",
      "Epoch 145/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1564 - conv1d_transpose_1_loss: 0.0207 - conv1d_transpose_3_loss: 0.1358 - val_loss: 0.1701 - val_conv1d_transpose_1_loss: 0.0233 - val_conv1d_transpose_3_loss: 0.1468\n",
      "Epoch 146/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1572 - conv1d_transpose_1_loss: 0.0211 - conv1d_transpose_3_loss: 0.1361 - val_loss: 0.1696 - val_conv1d_transpose_1_loss: 0.0232 - val_conv1d_transpose_3_loss: 0.1464\n",
      "Epoch 147/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1563 - conv1d_transpose_1_loss: 0.0201 - conv1d_transpose_3_loss: 0.1361 - val_loss: 0.1692 - val_conv1d_transpose_1_loss: 0.0230 - val_conv1d_transpose_3_loss: 0.1462\n",
      "Epoch 148/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1566 - conv1d_transpose_1_loss: 0.0208 - conv1d_transpose_3_loss: 0.1358 - val_loss: 0.1708 - val_conv1d_transpose_1_loss: 0.0249 - val_conv1d_transpose_3_loss: 0.1459\n",
      "Epoch 149/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1573 - conv1d_transpose_1_loss: 0.0218 - conv1d_transpose_3_loss: 0.1355 - val_loss: 0.1738 - val_conv1d_transpose_1_loss: 0.0278 - val_conv1d_transpose_3_loss: 0.1460\n",
      "Epoch 150/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1572 - conv1d_transpose_1_loss: 0.0216 - conv1d_transpose_3_loss: 0.1356 - val_loss: 0.1691 - val_conv1d_transpose_1_loss: 0.0232 - val_conv1d_transpose_3_loss: 0.1459\n",
      "Epoch 151/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1554 - conv1d_transpose_1_loss: 0.0203 - conv1d_transpose_3_loss: 0.1351 - val_loss: 0.1700 - val_conv1d_transpose_1_loss: 0.0231 - val_conv1d_transpose_3_loss: 0.1469\n",
      "Epoch 152/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1550 - conv1d_transpose_1_loss: 0.0203 - conv1d_transpose_3_loss: 0.1347 - val_loss: 0.1684 - val_conv1d_transpose_1_loss: 0.0231 - val_conv1d_transpose_3_loss: 0.1453\n",
      "Epoch 153/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1554 - conv1d_transpose_1_loss: 0.0211 - conv1d_transpose_3_loss: 0.134 - 0s 9ms/step - loss: 0.1541 - conv1d_transpose_1_loss: 0.0203 - conv1d_transpose_3_loss: 0.1337 - val_loss: 0.1683 - val_conv1d_transpose_1_loss: 0.0232 - val_conv1d_transpose_3_loss: 0.1451\n",
      "Epoch 154/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1542 - conv1d_transpose_1_loss: 0.0203 - conv1d_transpose_3_loss: 0.1339 - val_loss: 0.1691 - val_conv1d_transpose_1_loss: 0.0237 - val_conv1d_transpose_3_loss: 0.1454\n",
      "Epoch 155/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1539 - conv1d_transpose_1_loss: 0.0199 - conv1d_transpose_3_loss: 0.1339 - val_loss: 0.1686 - val_conv1d_transpose_1_loss: 0.0231 - val_conv1d_transpose_3_loss: 0.1456\n",
      "Epoch 156/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1542 - conv1d_transpose_1_loss: 0.0202 - conv1d_transpose_3_loss: 0.1340 - val_loss: 0.1670 - val_conv1d_transpose_1_loss: 0.0227 - val_conv1d_transpose_3_loss: 0.1443\n",
      "Epoch 157/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1535 - conv1d_transpose_1_loss: 0.0200 - conv1d_transpose_3_loss: 0.1335 - val_loss: 0.1674 - val_conv1d_transpose_1_loss: 0.0229 - val_conv1d_transpose_3_loss: 0.1445\n",
      "Epoch 158/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1539 - conv1d_transpose_1_loss: 0.0205 - conv1d_transpose_3_loss: 0.1334 - val_loss: 0.1705 - val_conv1d_transpose_1_loss: 0.0253 - val_conv1d_transpose_3_loss: 0.1452\n",
      "Epoch 159/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1538 - conv1d_transpose_1_loss: 0.0208 - conv1d_transpose_3_loss: 0.1329 - val_loss: 0.1675 - val_conv1d_transpose_1_loss: 0.0228 - val_conv1d_transpose_3_loss: 0.1446\n",
      "Epoch 160/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1530 - conv1d_transpose_1_loss: 0.0198 - conv1d_transpose_3_loss: 0.1332 - val_loss: 0.1678 - val_conv1d_transpose_1_loss: 0.0228 - val_conv1d_transpose_3_loss: 0.1450\n",
      "Epoch 161/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1528 - conv1d_transpose_1_loss: 0.0197 - conv1d_transpose_3_loss: 0.1331 - val_loss: 0.1683 - val_conv1d_transpose_1_loss: 0.0235 - val_conv1d_transpose_3_loss: 0.1449\n",
      "Epoch 162/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1519 - conv1d_transpose_1_loss: 0.0195 - conv1d_transpose_3_loss: 0.1324 - val_loss: 0.1663 - val_conv1d_transpose_1_loss: 0.0221 - val_conv1d_transpose_3_loss: 0.1442\n",
      "Epoch 163/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1513 - conv1d_transpose_1_loss: 0.0195 - conv1d_transpose_3_loss: 0.1318 - val_loss: 0.1654 - val_conv1d_transpose_1_loss: 0.0222 - val_conv1d_transpose_3_loss: 0.1432\n",
      "Epoch 164/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1509 - conv1d_transpose_1_loss: 0.0192 - conv1d_transpose_3_loss: 0.1317 - val_loss: 0.1655 - val_conv1d_transpose_1_loss: 0.0227 - val_conv1d_transpose_3_loss: 0.1428\n",
      "Epoch 165/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1519 - conv1d_transpose_1_loss: 0.0197 - conv1d_transpose_3_loss: 0.1322 - val_loss: 0.1656 - val_conv1d_transpose_1_loss: 0.0223 - val_conv1d_transpose_3_loss: 0.1433\n",
      "Epoch 166/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1508 - conv1d_transpose_1_loss: 0.0194 - conv1d_transpose_3_loss: 0.1314 - val_loss: 0.1648 - val_conv1d_transpose_1_loss: 0.0221 - val_conv1d_transpose_3_loss: 0.1427\n",
      "Epoch 167/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1511 - conv1d_transpose_1_loss: 0.0193 - conv1d_transpose_3_loss: 0.1318 - val_loss: 0.1658 - val_conv1d_transpose_1_loss: 0.0225 - val_conv1d_transpose_3_loss: 0.1433\n",
      "Epoch 168/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1509 - conv1d_transpose_1_loss: 0.0196 - conv1d_transpose_3_loss: 0.1313 - val_loss: 0.1655 - val_conv1d_transpose_1_loss: 0.0218 - val_conv1d_transpose_3_loss: 0.1437\n",
      "Epoch 169/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1517 - conv1d_transpose_1_loss: 0.0198 - conv1d_transpose_3_loss: 0.1319 - val_loss: 0.1664 - val_conv1d_transpose_1_loss: 0.0224 - val_conv1d_transpose_3_loss: 0.1440\n",
      "Epoch 170/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1509 - conv1d_transpose_1_loss: 0.0200 - conv1d_transpose_3_loss: 0.1309 - val_loss: 0.1664 - val_conv1d_transpose_1_loss: 0.0229 - val_conv1d_transpose_3_loss: 0.1435\n",
      "Epoch 171/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1509 - conv1d_transpose_1_loss: 0.0196 - conv1d_transpose_3_loss: 0.1313 - val_loss: 0.1652 - val_conv1d_transpose_1_loss: 0.0218 - val_conv1d_transpose_3_loss: 0.1434\n",
      "Epoch 172/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1499 - conv1d_transpose_1_loss: 0.0194 - conv1d_transpose_3_loss: 0.1305 - val_loss: 0.1635 - val_conv1d_transpose_1_loss: 0.0218 - val_conv1d_transpose_3_loss: 0.1417\n",
      "Epoch 173/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1496 - conv1d_transpose_1_loss: 0.0191 - conv1d_transpose_3_loss: 0.1305 - val_loss: 0.1644 - val_conv1d_transpose_1_loss: 0.0216 - val_conv1d_transpose_3_loss: 0.1428\n",
      "Epoch 174/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1498 - conv1d_transpose_1_loss: 0.0193 - conv1d_transpose_3_loss: 0.1304 - val_loss: 0.1648 - val_conv1d_transpose_1_loss: 0.0215 - val_conv1d_transpose_3_loss: 0.1433\n",
      "Epoch 175/200\n",
      "29/29 [==============================] - 0s 9ms/step - loss: 0.1492 - conv1d_transpose_1_loss: 0.0190 - conv1d_transpose_3_loss: 0.1302 - val_loss: 0.1643 - val_conv1d_transpose_1_loss: 0.0220 - val_conv1d_transpose_3_loss: 0.1423\n",
      "Epoch 176/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1496 - conv1d_transpose_1_loss: 0.0191 - conv1d_transpose_3_loss: 0.1305 - val_loss: 0.1639 - val_conv1d_transpose_1_loss: 0.0222 - val_conv1d_transpose_3_loss: 0.1417\n",
      "Epoch 177/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1495 - conv1d_transpose_1_loss: 0.0196 - conv1d_transpose_3_loss: 0.1299 - val_loss: 0.1643 - val_conv1d_transpose_1_loss: 0.0227 - val_conv1d_transpose_3_loss: 0.1416\n",
      "Epoch 178/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1488 - conv1d_transpose_1_loss: 0.0193 - conv1d_transpose_3_loss: 0.1295 - val_loss: 0.1636 - val_conv1d_transpose_1_loss: 0.0219 - val_conv1d_transpose_3_loss: 0.1417\n",
      "Epoch 179/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1485 - conv1d_transpose_1_loss: 0.0189 - conv1d_transpose_3_loss: 0.1296 - val_loss: 0.1651 - val_conv1d_transpose_1_loss: 0.0218 - val_conv1d_transpose_3_loss: 0.1433\n",
      "Epoch 180/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1487 - conv1d_transpose_1_loss: 0.0189 - conv1d_transpose_3_loss: 0.1297 - val_loss: 0.1634 - val_conv1d_transpose_1_loss: 0.0216 - val_conv1d_transpose_3_loss: 0.1418\n",
      "Epoch 181/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1475 - conv1d_transpose_1_loss: 0.0184 - conv1d_transpose_3_loss: 0.1291 - val_loss: 0.1635 - val_conv1d_transpose_1_loss: 0.0220 - val_conv1d_transpose_3_loss: 0.1415\n",
      "Epoch 182/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1477 - conv1d_transpose_1_loss: 0.0184 - conv1d_transpose_3_loss: 0.1293 - val_loss: 0.1635 - val_conv1d_transpose_1_loss: 0.0213 - val_conv1d_transpose_3_loss: 0.1422\n",
      "Epoch 183/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1485 - conv1d_transpose_1_loss: 0.0191 - conv1d_transpose_3_loss: 0.1295 - val_loss: 0.1633 - val_conv1d_transpose_1_loss: 0.0215 - val_conv1d_transpose_3_loss: 0.1418\n",
      "Epoch 184/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1485 - conv1d_transpose_1_loss: 0.0188 - conv1d_transpose_3_loss: 0.1296 - val_loss: 0.1628 - val_conv1d_transpose_1_loss: 0.0214 - val_conv1d_transpose_3_loss: 0.1413\n",
      "Epoch 185/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1473 - conv1d_transpose_1_loss: 0.0188 - conv1d_transpose_3_loss: 0.1285 - val_loss: 0.1624 - val_conv1d_transpose_1_loss: 0.0213 - val_conv1d_transpose_3_loss: 0.1411\n",
      "Epoch 186/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1475 - conv1d_transpose_1_loss: 0.0194 - conv1d_transpose_3_loss: 0.1281 - val_loss: 0.1621 - val_conv1d_transpose_1_loss: 0.0214 - val_conv1d_transpose_3_loss: 0.1407\n",
      "Epoch 187/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1467 - conv1d_transpose_1_loss: 0.0185 - conv1d_transpose_3_loss: 0.1282 - val_loss: 0.1612 - val_conv1d_transpose_1_loss: 0.0210 - val_conv1d_transpose_3_loss: 0.1402\n",
      "Epoch 188/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1464 - conv1d_transpose_1_loss: 0.0184 - conv1d_transpose_3_loss: 0.1281 - val_loss: 0.1622 - val_conv1d_transpose_1_loss: 0.0220 - val_conv1d_transpose_3_loss: 0.1402\n",
      "Epoch 189/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1472 - conv1d_transpose_1_loss: 0.0185 - conv1d_transpose_3_loss: 0.1287 - val_loss: 0.1614 - val_conv1d_transpose_1_loss: 0.0207 - val_conv1d_transpose_3_loss: 0.1407\n",
      "Epoch 190/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1466 - conv1d_transpose_1_loss: 0.0186 - conv1d_transpose_3_loss: 0.1280 - val_loss: 0.1621 - val_conv1d_transpose_1_loss: 0.0217 - val_conv1d_transpose_3_loss: 0.1403\n",
      "Epoch 191/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1462 - conv1d_transpose_1_loss: 0.0184 - conv1d_transpose_3_loss: 0.1278 - val_loss: 0.1625 - val_conv1d_transpose_1_loss: 0.0210 - val_conv1d_transpose_3_loss: 0.1415\n",
      "Epoch 192/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1465 - conv1d_transpose_1_loss: 0.0186 - conv1d_transpose_3_loss: 0.1279 - val_loss: 0.1625 - val_conv1d_transpose_1_loss: 0.0209 - val_conv1d_transpose_3_loss: 0.1415\n",
      "Epoch 193/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1457 - conv1d_transpose_1_loss: 0.0182 - conv1d_transpose_3_loss: 0.1275 - val_loss: 0.1613 - val_conv1d_transpose_1_loss: 0.0213 - val_conv1d_transpose_3_loss: 0.1400\n",
      "Epoch 194/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1464 - conv1d_transpose_1_loss: 0.0190 - conv1d_transpose_3_loss: 0.1274 - val_loss: 0.1621 - val_conv1d_transpose_1_loss: 0.0216 - val_conv1d_transpose_3_loss: 0.1405\n",
      "Epoch 195/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1460 - conv1d_transpose_1_loss: 0.0188 - conv1d_transpose_3_loss: 0.1272 - val_loss: 0.1606 - val_conv1d_transpose_1_loss: 0.0212 - val_conv1d_transpose_3_loss: 0.1394\n",
      "Epoch 196/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1459 - conv1d_transpose_1_loss: 0.0187 - conv1d_transpose_3_loss: 0.1273 - val_loss: 0.1640 - val_conv1d_transpose_1_loss: 0.0223 - val_conv1d_transpose_3_loss: 0.1417\n",
      "Epoch 197/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1461 - conv1d_transpose_1_loss: 0.0189 - conv1d_transpose_3_loss: 0.1272 - val_loss: 0.1605 - val_conv1d_transpose_1_loss: 0.0211 - val_conv1d_transpose_3_loss: 0.1394\n",
      "Epoch 198/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1450 - conv1d_transpose_1_loss: 0.0182 - conv1d_transpose_3_loss: 0.1268 - val_loss: 0.1610 - val_conv1d_transpose_1_loss: 0.0206 - val_conv1d_transpose_3_loss: 0.1404\n",
      "Epoch 199/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1454 - conv1d_transpose_1_loss: 0.0181 - conv1d_transpose_3_loss: 0.1273 - val_loss: 0.1606 - val_conv1d_transpose_1_loss: 0.0208 - val_conv1d_transpose_3_loss: 0.1397\n",
      "Epoch 200/200\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 0.1455 - conv1d_transpose_1_loss: 0.0180 - conv1d_transpose_3_loss: 0.1274 - val_loss: 0.1604 - val_conv1d_transpose_1_loss: 0.0205 - val_conv1d_transpose_3_loss: 0.1399\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "mask_pred_model = MaskPredModel(x_train)\n",
    "# Define early stopping callback to monitor validation loss and stop if it doesn't improve for 5 epochs\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model with 20 epochs and batch size of 32, using the early stopping callback\n",
    "history = mask_pred_model.fit(x_train_mask, [x_train,train_mask], epochs=200, batch_size=128, validation_data=(x_test_mask, [x_test,test_mask]), callbacks=[early_stop])\n",
    "\n",
    "# Plot the training history for loss and accuracy\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 10, 6)]           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 10, 32)            608       \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 10, 32)            3104      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 320)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,712\n",
      "Trainable params: 3,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(inputs=mask_pred_model.input,outputs=mask_pred_model.layers[3].output)\n",
    "encoder.compile()\n",
    "encoder.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune the AE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "Y_ohe = ohe.fit_transform(Y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FineTunedModel(nn_model,x_train,y_train,X_sc,Y_ohe,method='hybrid'):\n",
    "    # nn_model.compile()\n",
    "\n",
    "    from keras.layers import BatchNormalization\n",
    "    from keras.models import clone_and_build_model\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "    if method == 'hybrid':\n",
    "        model_copy= clone_and_build_model(nn_model)\n",
    "        model_copy.set_weights(weights=nn_model.get_weights())\n",
    "        intermediate_model = Model(inputs=model_copy.input,outputs=model_copy.layers[-2].output)\n",
    "    else:\n",
    "        intermediate_model = clone_and_build_model(nn_model)\n",
    "        intermediate_model.set_weights(weights=nn_model.get_weights())\n",
    "\n",
    "    for l in intermediate_model.layers:\n",
    "        l.trainable=False\n",
    "\n",
    "    fine_tuned_layers = Dense(units=64,activation='relu')(intermediate_model.output)\n",
    "    output_layer = Dense(units=Y_ohe.shape[1],activation='softmax')(fine_tuned_layers)\n",
    "\n",
    "    # Define the model\n",
    "    fine_tuned_model = Model(inputs=intermediate_model.input, outputs=output_layer)\n",
    "\n",
    "    # Compile the model with binary cross-entropy loss function and Adam optimizer\n",
    "    fine_tuned_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) #categorical_hinge\n",
    "\n",
    "    #train the model with freezed layer\n",
    "    fine_tuned_model.fit(x_train, y_train, epochs=500, batch_size=int(len(x_train) * 0.2), validation_data=(X_sc[::50], Y_ohe[::50]), callbacks=[early_stop], verbose=0)\n",
    "\n",
    "    for l in fine_tuned_model.layers:\n",
    "        l.trainable=True\n",
    "\n",
    "    # Create a custom Adam optimizer with a small learning rate\n",
    "    custom_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "    # Compiling again is necessary to update the trainable parameter before training\n",
    "    fine_tuned_model.compile(loss='categorical_crossentropy', optimizer=custom_optimizer, metrics=['accuracy']) #categorical_hinge\n",
    "\n",
    "    #train the model with freezed layer\n",
    "    fine_tuned_model.fit(x_train, y_train, epochs=50, batch_size=int(len(x_train) * 0.2), validation_data=(X_sc[::50], Y_ohe[::50]), callbacks=[early_stop], verbose=0)\n",
    "\n",
    "    return fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuned Model Training\n",
      "**************** repetation - 0 ****************\n",
      "Repetition 1: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.6910516415512217\n",
      "Repetition 1: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.7600633541801328\n",
      "Repetition 1: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.8490211063989973\n",
      "Repetition 1: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.8887483735950699\n",
      "Repetition 1: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.9121297497771146\n",
      "Repetition 1: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.9001827353631476\n",
      "**************** repetation - 1 ****************\n",
      "Repetition 2: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.6959008991822955\n",
      "Repetition 2: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.7450990299157363\n",
      "Repetition 2: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.8569008295789498\n",
      "Repetition 2: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.8854038895792413\n",
      "Repetition 2: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.9002465263494676\n",
      "Repetition 2: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.9101214650183722\n",
      "**************** repetation - 2 ****************\n",
      "Repetition 3: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.6594673516692311\n",
      "Repetition 3: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.7956331725539499\n",
      "Repetition 3: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.8526769917418842\n",
      "Repetition 3: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.8928990392353502\n",
      "Repetition 3: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.920271144895205\n",
      "Repetition 3: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.9123888221260366\n",
      "**************** repetation - 3 ****************\n",
      "Repetition 4: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.6727448902132185\n",
      "Repetition 4: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.7934691787035923\n",
      "Repetition 4: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.847387523468137\n",
      "Repetition 4: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.8909665834900358\n",
      "Repetition 4: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.9179421543414683\n",
      "Repetition 4: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.9101345876345877\n",
      "**************** repetation - 4 ****************\n",
      "Repetition 5: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.6702065002497563\n",
      "Repetition 5: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.7653657377364386\n",
      "Repetition 5: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.8504565038136468\n",
      "Repetition 5: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.896948387027183\n",
      "Repetition 5: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.9181290931290931\n",
      "Repetition 5: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.9121073554966899\n",
      "**************** repetation - 5 ****************\n",
      "Repetition 6: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.6825543974748529\n",
      "Repetition 6: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.804114969634967\n",
      "Repetition 6: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.8524824127149557\n",
      "Repetition 6: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.8989854843400696\n",
      "Repetition 6: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.9299509277850863\n",
      "Repetition 6: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.890559365214872\n",
      "**************** repetation - 6 ****************\n",
      "Repetition 7: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.6398340246198939\n",
      "Repetition 7: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.7547748884640197\n",
      "Repetition 7: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.8392978760145405\n",
      "Repetition 7: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.8944704768282129\n",
      "Repetition 7: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.9201869941973678\n",
      "Repetition 7: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.9200215279468326\n",
      "**************** repetation - 7 ****************\n",
      "Repetition 8: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.6765342574806793\n",
      "Repetition 8: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.7640984376990692\n",
      "Repetition 8: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.8539939264151266\n",
      "Repetition 8: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.9033609018796616\n",
      "Repetition 8: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.9301275882567739\n",
      "Repetition 8: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.896305806078556\n",
      "**************** repetation - 8 ****************\n",
      "Repetition 9: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.653396111719193\n",
      "Repetition 9: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.7786958843573671\n",
      "Repetition 9: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.8331231672201227\n",
      "Repetition 9: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.8887301540713077\n",
      "Repetition 9: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.9182137028135802\n",
      "Repetition 9: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.896105538233145\n",
      "**************** repetation - 9 ****************\n",
      "Repetition 10: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.6736116328326306\n",
      "Repetition 10: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.7851489824894459\n",
      "Repetition 10: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.838616093422133\n",
      "Repetition 10: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.9050528615581038\n",
      "Repetition 10: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.9202012340894479\n",
      "Repetition 10: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.9138832320883667\n",
      "F1 Scores Matrix:\n",
      "[[0.69105164 0.76006335 0.84902111 0.88874837 0.91212975 0.90018274]\n",
      " [0.6959009  0.74509903 0.85690083 0.88540389 0.90024653 0.91012147]\n",
      " [0.65946735 0.79563317 0.85267699 0.89289904 0.92027114 0.91238882]\n",
      " [0.67274489 0.79346918 0.84738752 0.89096658 0.91794215 0.91013459]\n",
      " [0.6702065  0.76536574 0.8504565  0.89694839 0.91812909 0.91210736]\n",
      " [0.6825544  0.80411497 0.85248241 0.89898548 0.92995093 0.89055937]\n",
      " [0.63983402 0.75477489 0.83929788 0.89447048 0.92018699 0.92002153]\n",
      " [0.67653426 0.76409844 0.85399393 0.9033609  0.93012759 0.89630581]\n",
      " [0.65339611 0.77869588 0.83312317 0.88873015 0.9182137  0.89610554]\n",
      " [0.67361163 0.78514898 0.83861609 0.90505286 0.92020123 0.91388323]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "set_of_samples = [4, 8, 16, 32, 64, 90]\n",
    "num_repetitions = 10\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "print(\"FineTuned Model Training\")\n",
    "F1_score_finetuned = np.zeros((num_repetitions, len(set_of_samples)))\n",
    "\n",
    "for repetition in range(num_repetitions):\n",
    "    print(f\"**************** repetation - {repetition} ****************\")\n",
    "    for i, samples in enumerate(set_of_samples):\n",
    "        print(f'Repetition {repetition + 1}: Training samples per class = {samples}')\n",
    " \n",
    "        x_val, y_val, _ = resample(X_sc, Y, Z, samples)\n",
    "        y_val = ohe.transform(y_val.reshape(-1, 1))\n",
    "\n",
    "        fine_tuned_model = FineTunedModel(encoder,x_val,y_val,X_sc,Y_ohe,method='sota2')\n",
    "        \n",
    "        x_train,y_train,z_train = resample(X,Y,Z,50)\n",
    "        x_train = sc.transform(x_train.reshape(-1,x_train.shape[2])).reshape(x_train.shape)\n",
    "        \n",
    "        y_pred = fine_tuned_model.predict(x_train)\n",
    "        y_pred = ohe.inverse_transform(y_pred)\n",
    "        f1 = f1_score(y_train, y_pred, average='macro')\n",
    "        print(f'F1 score on whole dataset = {f1}')\n",
    "        F1_score_finetuned[repetition, i] = f1\n",
    "\n",
    "print(\"F1 Scores Matrix:\")\n",
    "print(F1_score_finetuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the experiment in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_f1_scores_ae = np.mean(F1_score_finetuned, axis=0)\n",
    "variance_f1_scores_ae= np.var(F1_score_finetuned, axis=0)\n",
    "\n",
    "results_dict = {\n",
    "    'No training samples': set_of_samples,\n",
    "    'Model': ['SOA2'] * len(set_of_samples) ,\n",
    "    'Mean F1 score': mean_f1_scores_ae,\n",
    "    'Error': variance_f1_scores_ae\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv('SOA2_mask_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The proposed hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propose hybrid method\n",
      "Repetition 1: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.8465246256118677\n",
      "Repetition 1: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.870915360624599\n",
      "Repetition 1: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.8728452753044804\n",
      "Repetition 1: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.890880816395274\n",
      "Repetition 1: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.9021268156819208\n",
      "Repetition 1: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.9123999979784452\n",
      "Repetition 2: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.8289303141262172\n",
      "Repetition 2: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.8590626186545322\n",
      "Repetition 2: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.8852700309168309\n",
      "Repetition 2: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.9063814256411964\n",
      "Repetition 2: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.8999285961732518\n",
      "Repetition 2: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.8976706441281307\n",
      "Repetition 3: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.8384511742415253\n",
      "Repetition 3: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.8586438242192065\n",
      "Repetition 3: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.8822024009828227\n",
      "Repetition 3: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.8999307226745618\n",
      "Repetition 3: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.8965061836551493\n",
      "Repetition 3: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.9021072127322262\n",
      "Repetition 4: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.8270204799604833\n",
      "Repetition 4: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.8590051849080721\n",
      "Repetition 4: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.8832244218371998\n",
      "Repetition 4: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.8976898427146607\n",
      "Repetition 4: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.9065597685294475\n",
      "Repetition 4: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.8942795125535496\n",
      "Repetition 5: Training samples per class = 4\n",
      "F1 score on whole dataset = 0.8517118170185929\n",
      "Repetition 5: Training samples per class = 8\n",
      "F1 score on whole dataset = 0.8628809904509183\n",
      "Repetition 5: Training samples per class = 16\n",
      "F1 score on whole dataset = 0.8826953911642537\n",
      "Repetition 5: Training samples per class = 32\n",
      "F1 score on whole dataset = 0.8922816963982388\n",
      "Repetition 5: Training samples per class = 64\n",
      "F1 score on whole dataset = 0.906286379603985\n",
      "Repetition 5: Training samples per class = 90\n",
      "F1 score on whole dataset = 0.9024217036965453\n",
      "F1 Scores Matrix:\n",
      "[[0.84652463 0.87091536 0.87284528 0.89088082 0.90212682 0.9124    ]\n",
      " [0.82893031 0.85906262 0.88527003 0.90638143 0.8999286  0.89767064]\n",
      " [0.83845117 0.85864382 0.8822024  0.89993072 0.89650618 0.90210721]\n",
      " [0.82702048 0.85900518 0.88322442 0.89768984 0.90655977 0.89427951]\n",
      " [0.85171182 0.86288099 0.88269539 0.8922817  0.90628638 0.9024217 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create fullySupervided NEtwork\n",
    "print(\"Propose hybrid method\")\n",
    "F1_score_hybrid = np.zeros((num_repetitions, len(set_of_samples)))\n",
    "\n",
    "for repetition in range(num_repetitions):\n",
    "    for i, samples in enumerate(set_of_samples):\n",
    "        print(f'Repetition {repetition + 1}: Training samples per class = {samples}')\n",
    "        x_val, y_val, _ = resample(X_sc, Y,Z, samples)\n",
    "        y_val_ohe = ohe.transform(y_val.reshape(-1, 1))\n",
    "\n",
    "        hybrid_model = FineTunedModel(psuedo_label_model,x_val,y_val_ohe,X_sc,Y_ohe)\n",
    "        \n",
    "        x_train,y_train,z_train = resample(X,Y,Z,50)\n",
    "        x_train = sc.transform(x_train.reshape(-1,x_train.shape[2])).reshape(x_train.shape)\n",
    "        \n",
    "        y_pred = hybrid_model.predict(x_train)\n",
    "        y_pred = ohe.inverse_transform(y_pred)\n",
    "        y_pred = Cascade_Hybrid_FDI(x_train,z_train,y_pred)\n",
    "        f1 = f1_score(y_train, y_pred, average='macro')\n",
    "        print(f'F1 score on whole dataset = {f1}')\n",
    "        F1_score_hybrid[repetition, i] = f1\n",
    "\n",
    "print(\"F1 Scores Matrix:\")\n",
    "print(F1_score_hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABPFUlEQVR4nO3deViN+f8/8OdpO+1laTmRIhQyUUayFAYxxjZmxKBkN8xkmmH0MWT3YawzjMx8LI01jHWYMH2FMMxkN3aRoRJpp3LO/fvDzz2O9pw6dfd8XNe5ru73/b7P/brvTvXsfW8yQRAEEBEREUmEjrYLICIiItIkhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyKqcjp27IiOHTtW+Hrv3r0LmUyG9evXV/i6S2vYsGFwdHQscV9TU9PyLUhDSrNdVH0x3JBGrV+/HjKZrMDXlClTxH6HDh3CiBEj4OrqCl1d3VL/ssrMzERoaChcXV1hYmKCWrVqoUWLFggKCsLDhw81vFXSlJycjKCgILi4uMDIyAjW1tZo3bo1vv76a2RmZmq7vAq3b98++Pj4wNraGsbGxmjQoAEGDBiAyMhIbZemEdnZ2ZgxYwaio6M19p6PHj2Cnp4ehgwZUmifjIwMGBkZ4cMPP9TYeomKo6ftAkiaZs2ahfr166u1ubq6il9v3rwZERERcHd3h52dXaneOy8vD97e3rh27RoCAgLw2WefITMzE1euXMHmzZvRr1+/Ur9ndZOSkoJWrVohPT0dw4cPh4uLC548eYKLFy9i1apVGDduXJX5T14TFi1ahEmTJsHHxwchISEwNjbGrVu38Pvvv2Pr1q3o3r07AMDBwQHPnj2Dvr6+lisu3k8//QSVSiVOZ2dnY+bMmQCgsVEva2trdO3aFXv27EF2djaMjY3z9dm5cyeeP39eZAAqjTe3i6ggDDdULnr06IFWrVoVOn/evHn46aefoK+vjw8++ACXL18u8Xvv3r0b586dw6ZNm/DJJ5+ozXv+/Dlyc3PLXHdpZWVlwcTEpMLWpylr1qxBfHw8Tpw4gbZt26rNS09Ph4GBgZYqq3gvXrzA7Nmz0bVrVxw6dCjf/EePHolfy2QyGBoaVmR5ZVZRAWzw4MGIjIzE3r17MXDgwHzzN2/eDAsLC/Ts2fOt1vPqZ60qBEvSPh6WIq2ws7Mr8y+p27dvAwDatWuXb56hoSHMzc3V2q5du4YBAwbAysoKRkZGcHZ2xtSpU9X6nDt3Dj169IC5uTlMTU3x3nvv4Y8//lDr8+qQ29GjR/Hpp5/C2toadevWFef/9ttv6NChA0xMTGBmZoaePXviypUrRW7LX3/9BZlMhvDw8HzzDh48CJlMhl9//RXAy+H9iRMnwtHREXK5XPyv+ezZs0WuoyC3b9+Grq4u2rRpk2+eubm52h/w48eP4+OPP0a9evUgl8thb2+PL774As+ePVNb7tV5G/Hx8fjggw9gamqKOnXqYOXKlQCAS5cuoXPnzjAxMYGDgwM2b96stvyr/Xvs2DGMGTMGtWrVgrm5Ofz9/fH06dNityknJwehoaFo2LChWOfkyZORk5NT5HKPHz9Genp6gZ8n4OXoxCtvnnMTHR1d6GHYNw+1luXzkZqaCl1dXXz33Xdq9ero6KBWrVoQBEFsHzduHGxtbcXp189NuXv3LqysrAAAM2fOFGucMWOG2voePHiAvn37wtTUFFZWVvjqq6+gVCqLrLFfv34wMTHJ9/0EXgbDqKgofPTRR5DL5aX+LN2+fRvvv/8+zMzMMHjw4Hzb9cqiRYvQtm1b1KpVC0ZGRvDw8MCOHTvy1SOTyTBhwgTs3r0brq6ukMvlaNasWYGHHh88eIARI0bAzs4Ocrkc9evXx7hx49T+eUpNTcXEiRNhb28PuVyOhg0bYsGCBRxZqgQ4ckPlIi0tDY8fP1Zrq127tkbe28HBAQDw888/45tvvoFMJiu078WLF9GhQwfo6+tj9OjRcHR0xO3bt7Fv3z7MnTsXAHDlyhV06NAB5ubmmDx5MvT19bF69Wp07NgRR48ehaenp9p7fvrpp7CyssL06dORlZUFANiwYQMCAgLg6+uLBQsWIDs7G6tWrUL79u1x7ty5Qs8patWqFRo0aIBt27YhICBAbV5ERARq1KgBX19fAMDYsWOxY8cOTJgwAU2bNsWTJ08QExODq1evwt3dvdT7UKlUinUXZfv27cjOzsa4ceNQq1YtnDlzBt9//z3++ecfbN++Xa2vUqlEjx494O3tjYULF2LTpk2YMGECTExMMHXqVAwePBgffvghwsLC4O/vDy8vr3yHLydMmABLS0vMmDED169fx6pVq3Dv3j0xSBREpVKhd+/eiImJwejRo9GkSRNcunQJS5cuxY0bN7B79+5Ct8/a2hpGRkbYt28fPvvsM9SsWbNkOxFAkyZNsGHDBrW21NRUBAcHq4Wisn4+LC0t4erqimPHjuHzzz8HAMTExEAmkyElJQV///03mjVrBuBlCO3QoUOB72NlZSUebuzXr594/ss777wj9lEqlfD19YWnpycWLVqE33//HYsXL4aTkxPGjRtX6D4wMTFBnz59sGPHDqSkpKjtv4iICCiVSjGYlOaz9OLFC/j6+qJ9+/ZYtGhRgYe8Xlm+fDl69+6NwYMHIzc3F1u3bsXHH3+MX3/9Nd+IUUxMDHbu3IlPP/0UZmZm+O6779C/f3/Ex8ejVq1aAICHDx+idevWSE1NxejRo+Hi4oIHDx5gx44dyM7OhoGBAbKzs+Hj44MHDx5gzJgxqFevHk6ePImQkBAkJCRg2bJlhdZLFUAg0qB169YJAAp8FaZnz56Cg4NDideRnZ0tODs7CwAEBwcHYdiwYcKaNWuEpKSkfH29vb0FMzMz4d69e2rtKpVK/Lpv376CgYGBcPv2bbHt4cOHgpmZmeDt7Z1v29q3by+8ePFCbM/IyBAsLS2FUaNGqa0jMTFRsLCwyNf+ppCQEEFfX19ISUkR23JycgRLS0th+PDhYpuFhYUwfvz4It+rpBITEwUrKysBgODi4iKMHTtW2Lx5s5Campqvb3Z2dr62+fPnCzKZTG2/BgQECACEefPmiW1Pnz4VjIyMBJlMJmzdulVsv3btmgBACA0NFdte7V8PDw8hNzdXbF+4cKEAQNizZ4/Y5uPjI/j4+IjTGzZsEHR0dITjx4+r1RkWFiYAEE6cOFHk/pg+fboAQDAxMRF69OghzJ07V4iNjc3XLy4uTgAgrFu3rsD3UalUwgcffCCYmpoKV65cEQTh7T8f48ePF2xsbMTp4OBgwdvbW7C2thZWrVolCIIgPHnyRJDJZMLy5cvFfgEBAWo/V8nJyfn2+et9AQizZs1Sa2/ZsqXg4eFRZH2CIAj79+8XAAirV69Wa2/Tpo1Qp04dQalUCoJQ+s/SlClTCqz1zd8Xb75vbm6u4OrqKnTu3FmtHYBgYGAg3Lp1S2y7cOGCAED4/vvvxTZ/f39BR0dH+PPPP/Ot/9XvjtmzZwsmJibCjRs31OZPmTJF0NXVFeLj4/MtSxWHh6WoXKxcuRKHDx9We2mKkZERTp8+jUmTJgF4eThjxIgRUCgU+Oyzz8TDEMnJyTh27BiGDx+OevXqqb3HqxEApVKJQ4cOoW/fvmjQoIE4X6FQ4JNPPkFMTAzS09PVlh01ahR0dXXF6cOHDyM1NRWDBg3C48ePxZeuri48PT1x5MiRIrfHz88PeXl52Llzp9h26NAhpKamws/PT2yztLTE6dOnNXI1mI2NDS5cuICxY8fi6dOnCAsLwyeffAJra2vMnj1b7XCHkZGR+HVWVhYeP36Mtm3bQhAEnDt3Lt97jxw5Uq1mZ2dnmJiYYMCAAWK7s7MzLC0tcefOnXzLjx49Wu2Q5bhx46Cnp4cDBw4Uuj3bt29HkyZN4OLiovY96Ny5MwAU+z2YOXMmNm/ejJYtW+LgwYOYOnUqPDw84O7ujqtXrxa57Otmz56NX3/9FevXr0fTpk0BvP3no0OHDkhKSsL169cBvByh8fb2RocOHXD8+HEAL0cjBEEodOSmpMaOHZtv3QV9j97UrVs3WFlZqR2aiouLwx9//IFBgwZBR+fln5rSfpaKGjF63evv+/TpU6SlpaFDhw4FHrLt0qULnJycxOl33nkH5ubm4naqVCrs3r0bvXr1KvC8wVe/O7Zv344OHTqgRo0aat/XLl26QKlU4tixYyWqncoHD0tRuWjdunWRJxS/LQsLCyxcuBALFy7EvXv3EBUVhUWLFmHFihWwsLDAnDlzxF9Wr1+l9abk5GRkZ2fD2dk537wmTZpApVLh/v374tA/gHyHUW7evAkA4h/SN715DtCb3Nzc4OLigoiICIwYMQLAy+H82rVrq73nwoULERAQAHt7e3h4eOD999+Hv7+/WigrDYVCgVWrVuGHH37AzZs3cfDgQSxYsADTp0+HQqEQQ0p8fDymT5+OvXv35jv3JS0tTW3a0NBQPLfjFQsLC9StWzffISULC4sCz6Vp1KiR2rSpqSkUCgXu3r1b6LbcvHkTV69ezbfuV14/KbgwgwYNwqBBg5Ceno7Tp09j/fr12Lx5M3r16oXLly8XeyJxZGQkZs6ciZCQEPTv31+tNqDsn49XgeX48eOoW7cuzp07hzlz5sDKygqLFi0S55mbm8PNza3Y7SxMQd+7GjVqlOh8Jz09Pfj5+eGHH37AgwcPUKdOHTHovDokBZTus6Snp6d2TltRfv31V8yZMwfnz59XO8eqoMOYb/6jA6hvZ3JyMtLT04v8vQG8/L5evHjxrT5zVH4YbqjKc3BwwPDhw9GvXz80aNAAmzZtwpw5c8ptfa//lwhAPHlww4YNaid0vqKnV/yPmZ+fH+bOnYvHjx/DzMwMe/fuxaBBg9SWHTBgADp06IBdu3bh0KFD+Pbbb7FgwQLs3LkTPXr0KPP2yGQyNG7cGI0bN0bPnj3RqFEjbNq0CSNHjoRSqUTXrl2RkpKCr7/+Gi4uLjAxMcGDBw8wbNiwfCdOvj6iVZL210eI3oZKpULz5s2xZMmSAufb29uX+L3Mzc3RtWtXdO3aFfr6+ggPD8fp06fh4+NT6DJxcXEYPHgwunbtmu+z97afDzs7O9SvXx/Hjh2Do6MjBEGAl5cXrKysEBQUhHv37uH48eNo27atOEJSFoV9j0pqyJAhWLFiBbZs2YKvvvoKW7ZsQdOmTdGiRQsAKPVnSS6Xl2h7jh8/jt69e8Pb2xs//PADFAoF9PX1sW7dugJPctbUZ1GlUqFr166YPHlygfMbN25cqvcjzWK4IcmoUaMGnJycxMvKX41oFHWZuZWVFYyNjcUh/9ddu3YNOjo6xf5hfDXEbW1tjS5dupSpdj8/P8ycORO//PILbGxskJ6eXuBltQqFAp9++ik+/fRTPHr0CO7u7pg7d+5bhZvXNWjQADVq1EBCQgKAl1c43bhxA+Hh4fD39xf7afIw45tu3ryJTp06idOZmZlISEjA+++/X+gyTk5OuHDhAt57770iTzAvrVatWiE8PFzcHwV59uwZPvzwQ1haWmLLli35/iBr4vPRoUMHHDt2DPXr10eLFi1gZmYGNzc3WFhYIDIyEmfPnhXvYVMYTe6Xgnh6esLJyQmbN29G165dceXKFfGkfaD8Pku//PILDA0NcfDgQcjlcrF93bp1ZXo/KysrmJubF3t7CicnJ2RmZpb5e0rli+fcUJVz4cKFfFdiAcC9e/fw999/i4eYrKys4O3tjbVr1yI+Pl6t76v/0nR1ddGtWzfs2bNH7bBHUlISNm/ejPbt2xd72MDX1xfm5uaYN28e8vLy8s1PTk4udpuaNGmC5s2bIyIiAhEREVAoFPD29hbnK5XKfMP21tbWsLOzUxuGf/z4Ma5du4bs7Owi13f69GnxSq/XnTlzBk+ePBH34av/cl//r1YQBCxfvrzYbSqrH3/8UW0/rlq1Ci9evCgywA0YMAAPHjzATz/9lG/es2fPCtzWV7Kzs3Hq1KkC5/32228AUOBhy1fGjh2LGzduYNeuXahRo0a++Zr4fHTo0AF3795FRESEeJhKR0cHbdu2xZIlS5CXl1fs+TavrjZKTU0tdn1lNXjwYJw7dw6hoaGQyWRq96Eqr8+Srq4uZDKZ2iXrd+/eLfIKuaLo6Oigb9++2LdvH/76669881/VP2DAAJw6dQoHDx7M1yc1NRUvXrwo0/pJMzhyQ1px8eJF7N27FwBw69YtpKWlicP5bm5u6NWrV6HLHj58GKGhoejduzfatGkDU1NT3LlzB2vXrkVOTo7avTu+++47tG/fHu7u7hg9ejTq16+Pu3fvYv/+/Th//jwAYM6cOTh8+DDat2+PTz/9FHp6eli9ejVycnKwcOHCYrfF3Nwcq1atwtChQ+Hu7o6BAwfCysoK8fHx2L9/P9q1a4cVK1YU+z5+fn6YPn06DA0NMWLECLURgIyMDNStWxcfffQR3NzcYGpqit9//x1//vknFi9eLPZbsWIFZs6ciSNHjhR5F9oNGzZg06ZN6NevHzw8PGBgYICrV69i7dq1MDQ0xH/+8x8AgIuLC5ycnPDVV1/hwYMHMDc3xy+//FKi8zDKKjc3F++99x4GDBiA69ev44cffkD79u3Ru3fvQpcZOnQotm3bhrFjx+LIkSNo164dlEolrl27hm3btuHgwYOFngOWnZ2Ntm3bok2bNujevTvs7e2RmpqK3bt34/jx4+jbty9atmxZ4LL79+/Hzz//jP79++PixYu4ePGiOM/U1BR9+/bVyOfjVXC5fv065s2bJ7Z7e3vjt99+g1wux7vvvlvkexgZGaFp06aIiIhA48aNUbNmTbi6uhZ7bklpDBkyBLNmzcKePXvQrl07tUvcy+uz1LNnTyxZsgTdu3fHJ598gkePHmHlypVo2LCh2vejNObNm4dDhw7Bx8dHvLVAQkICtm/fjpiYGFhaWmLSpEnYu3cvPvjgAwwbNgweHh7IysrCpUuXsGPHDty9e1djt7+gMtDKNVokWa8u5y3oEsqC+hX0CggIKHLZO3fuCNOnTxfatGkjWFtbC3p6eoKVlZXQs2dP4f/+7//y9b98+bLQr18/wdLSUjA0NBScnZ2FadOmqfU5e/as4OvrK5iamgrGxsZCp06dhJMnT5Zq244cOSL4+voKFhYWgqGhoeDk5CQMGzZM+Ouvv4rcnldu3rwp7oOYmBi1eTk5OcKkSZMENzc3wczMTDAxMRHc3NyEH374Qa1faGioAEA4cuRIkeu6ePGiMGnSJMHd3V2oWbOmoKenJygUCuHjjz8Wzp49q9b377//Frp06SKYmpoKtWvXFkaNGiVePvv6JdEBAQGCiYlJvnX5+PgIzZo1y9fu4OAg9OzZU5x+tX+PHj0qjB49WqhRo4ZgamoqDB48WHjy5Em+93z9UnBBeHn574IFC4RmzZoJcrlcqFGjhuDh4SHMnDlTSEtLK3Rf5OXlCT/99JPQt29fwcHBQZDL5YKxsbHQsmVL4dtvvxVycnLEvm9eCl7U5/jNy5Xf9vNhbW0tAFC75UFMTIwAQOjQoUO+/gVdMn3y5EnBw8NDMDAwULssvLDv3avPU2m8++67AoB8n01BePvPUmHbtWbNGqFRo0aCXC4XXFxchHXr1hVYO4ACb6fg4OCQ7/fOvXv3BH9/f8HKykqQy+VCgwYNhPHjx6t9HjIyMoSQkBChYcOGgoGBgVC7dm2hbdu2wqJFi9RuZ0AVTyYIGjqjj4joLaxfvx6BgYH4888/y/VKOyKSPp5zQ0RERJLCcENERESSwnBDREREkqLVcHPs2DH06tULdnZ2kMlkJbp0Lzo6Gu7u7uITWF89nZeIqrZhw4ZBEASeb0NEb02r4SYrKwtubm5YuXJlifrHxcWhZ8+e6NSpE86fP4+JEydi5MiRBd5ngIiIiKqnSnO1lEwmw65du9C3b99C+3z99dfYv3+/2p0jBw4ciNTUVERGRlZAlURERFTZVamb+J06dSrfra59fX0xceLEQpfJyclRu4OrSqVCSkoKatWqVe63IyciIiLNEAQBGRkZsLOzK/a5Y1Uq3CQmJsLGxkat7dVzeJ49e5bvgYYAMH/+/GKfuUJERERVw/3794t9YnyVCjdlERISguDgYHE6LS0N9erVw/3794t9ZhARERFVDunp6bC3t4eZmVmxfatUuLG1tUVSUpJaW1JSEszNzQsctQEAuVyu9qTYV8zNzRluiIiIqpiSnFJSpe5z4+XlhaioKLW2w4cPw8vLS0sVERERUWWj1XCTmZmJ8+fPi09njouLw/nz5xEfHw/g5SElf39/sf/YsWNx584dTJ48GdeuXcMPP/yAbdu24YsvvtBG+URERFQJaTXc/PXXX2jZsiVatmwJAAgODkbLli0xffp0AEBCQoIYdACgfv362L9/Pw4fPgw3NzcsXrwY//vf/+Dr66uV+omIiKjyqTT3uako6enpsLCwQFpaWpHn3CiVSuTl5VVgZdWXvr4+dHV1tV0GERFVYiX9+w1UsROKK4IgCEhMTERqaqq2S6lWLC0tYWtry3sPERHRW2O4ecOrYGNtbQ1jY2P+sS1ngiAgOzsbjx49AgAoFAotV0RERFUdw81rlEqlGGxq1aql7XKqjVeX8T969AjW1tY8REVERG+lSl0KXt5enWNjbGys5Uqqn1f7nOc5ERHR22K4KQAPRVU87nMiItIUhhsiIiKSFIYbiejYsWORT0cvr+Xv3r0LmUwm3oixINHR0ZDJZLwCjYiIKgRPKC6pGRYVvL60il1fGdnb2yMhIQG1a9fWdilEREQAGG7oLeTm5sLAwAC2trbaLoWIiEjEw1ISolKpMHnyZNSsWRO2traYMWMGAGD48OH44IMP1Prm5eXB2toaa9asEdtevHiBCRMmwMLCArVr18a0adPw+g2sHR0dMXv2bPj7+8Pc3ByjR48u8LDUgQMH0LhxYxgZGaFTp064e/dueW42ERGRGoYbCQkPD4eJiQlOnz6NhQsXYtasWTh8+DBGjhyJyMhIJCQkiH1//fVXZGdnw8/PT215PT09nDlzBsuXL8eSJUvwv//9T20dixYtgpubG86dO4dp06blq+H+/fv48MMP0atXL5w/fx4jR47ElClTym+jiYiI3sBwIyHvvPMOQkND0ahRI/j7+6NVq1aIiopC27Zt4ezsjA0bNoh9161bh48//himpqZim729PZYuXQpnZ2cMHjwYn332GZYuXaq2js6dO+PLL7+Ek5MTnJyc8tWwatUqODk5YfHixeL7DBs2rNy2mYiI6E0MNxLyzjvvqE0rFArxsQYjR47EunXrAABJSUn47bffMHz4cLX+bdq0UbvfjJeXF27evAmlUim2tWrVqsgarl69Ck9PT7U2Ly+v0m8MERFRGTHcSIi+vr7atEwmg0qlAgD4+/vjzp07OHXqFDZu3Ij69eujQ4cOpV6HiYmJRmolIiIqL7xaqpqoVasW+vbti3Xr1uHUqVMIDAzM1+f06dNq03/88QcaNWpUqmc9NWnSBHv37s33PkRERBWFIzfVyMiRIxEeHo6rV68iICAg3/z4+HgEBwfj+vXr2LJlC77//nsEBQWVah1jx47FzZs3MWnSJFy/fh2bN2/G+vXrNbQFRERExWO4qUa6dOkChUIBX19f2NnZ5Zvv7++PZ8+eoXXr1hg/fjyCgoIwevToUq2jXr16+OWXX7B79264ubkhLCwM8+bN09QmEBERFUsmvH4jk2ogPT0dFhYWSEtLg7m5udq858+fIy4uDvXr14ehoaGWKiw/mZmZqFOnDtatW4cPP/xQ2+Wokfq+JyKit1PU3+838ZybakClUuHx48dYvHgxLC0t0bt3b22XREREVG4YbqqB+Ph41K9fH3Xr1sX69euhp8dvOxERSRf/ylUDjo6OqGZHH4mIqBrjCcVEREQkKQw3REREJCkMN0RERCQpDDdEREQkKQw3REREJCkMN0RERCQpDDdEREQkKbzPTQk1D29eoeu7FHCp1MskJydj+vTp2L9/P5KSklCjRg24ublh+vTpaNeuHQDg5MmTmDNnDk6dOoVnz56hUaNGCAwMRFBQUIFP/3ZxcUFcXBzu3bsHW1tbREdHo1OnTkXWceTIEaSkpGDVqlU4f/48cnJy0KxZM8yYMQO+vr6l3i4iIqLS4MiNhPTv3x/nzp1DeHg4bty4gb1796Jjx4548uQJAGDXrl3w8fFB3bp1ceTIEVy7dg1BQUGYM2cOBg4cmO9GfzExMXj27Bk++ugjhIeHAwDatm2LhIQE8TVgwAB0795dra1t27Y4duwYunbtigMHDiA2NhadOnVCr169cO7cuQrfL0REVL3wwZmvKerhjZV95CY1NRU1atRAdHQ0fHx88s3PysqCg4MDfHx88Msvv6jN27dvH3r37o2tW7fCz89PbA8MDIStrS18fHwQFBSE69ev53vfYcOGITU1Fbt37y62xmbNmsHPzw/Tp0/PN48PziQioqKU5sGZHLmRCFNTU5iammL37t3IycnJN//QoUN48uQJvvrqq3zzevXqhcaNG2PLli1iW0ZGBrZv344hQ4aga9euSEtLw/Hjx8tcn0qlQkZGBmrWrFnm9yAiIioJhhuJ0NPTw/r16xEeHg5LS0u0a9cO//nPf3Dx4kUAwI0bNwAATZo0KXB5FxcXsQ8AbN26FY0aNUKzZs2gq6uLgQMHYs2aNWWub9GiRcjMzMSAAQPK/B5EREQlwXAjIf3798fDhw+xd+9edO/eHdHR0XB3d8f69evFPiU9Crl27VoMGTJEnB4yZAi2b9+OjIyMUte1efNmzJw5E9u2bYO1tXWplyciIioNhhuJMTQ0RNeuXTFt2jScPHkSw4YNQ2hoKBo3bgwAuHr1aoHLXb16Vezz999/448//sDkyZOhp6cHPT09tGnTBtnZ2di6dWup6tm6dStGjhyJbdu2oUuXLm+3cURERCXAcCNxTZs2RVZWFrp164aaNWti8eLF+frs3bsXN2/exKBBgwAAa9asgbe3Ny5cuIDz58+Lr+Dg4FIdmtqyZQsCAwOxZcsW9OzZU2PbREREVBSGG4l48uQJOnfujI0bN+LixYuIi4vD9u3bsXDhQvTp0wcmJiZYvXo19uzZg9GjR+PixYu4e/cu1qxZg2HDhuGjjz7CgAEDkJeXhw0bNmDQoEFwdXVVe40cORKnT5/GlStXiq1n8+bN8Pf3x+LFi+Hp6YnExEQkJiYiLS2tAvYGERFVZww3EmFqagpPT08sXboU3t7ecHV1xbRp0zBq1CisWLECAPDRRx/hyJEjiI+PR4cOHeDs7IylS5di6tSp2Lp1K2QyGfbu3YsnT56gX79++dbRpEkTNGnSpESjNz/++CNevHiB8ePHQ6FQiK+goCCNbzsREdHreJ+b1/BeK9rDfU9EREXhfW6IiIio2mK4ISIiIklhuCEiIiJJ4VPBiYhIcl49yLcwry5yIGliuClANTvHulLgPiciTVq9ejVmzpxZ6PzQ0FDMmDGj4gqiCsVw8xp9fX0AQHZ2NoyMjLRcTfWSnZ0N4N/vARHR2xgzZgx69+6NZ8+eoX379gCAmJgY8Xc7R22kjeHmNbq6urC0tMSjR48AAMbGxpDJZFquStoEQUB2djYePXoES0tL6OrqarskIpKAV4edsrKyxLYWLVrAxMREi1VRRWG4eYOtrS0AiAGHKoalpaW474mIiN4Gw80bZDIZFAoFrK2tkZeXp+1yqgV9fX2O2BARkcYw3BRCV1eXf3CJiCqx5uHNi+2jylGJX7fe1Bo68qLvgHIp4NJb10Xax/vcEBERkaQw3BAREZGk8LAUERFJTl5qHl6kvoAq79/DUs/in0FH/+X/9HqWetC35K0nilKVb4TIcENERJKTciQFyXuS1dri5saJX1v1sYJNP5uKLqtKqco3QmS4ISIiyanZqSbMW5oXOl/Pkn/+ilOVb4TI7y4REUmOvqU+Dzu9pap8I0SeUExERESSwnBDREREksJwQ0RERJLCc26IiIiqseLu9FzauzwD2r/TM0duiIiISFI4ckNERCQBVfmme5rGcENERCQBVfmme5rGcENERFrFEQfNqMo33dM0rZ9zs3LlSjg6OsLQ0BCenp44c+ZMoX3z8vIwa9YsODk5wdDQEG5uboiMjKzAaomISNNWr14NDw+PQl+rV6/WdolVgkKhgLu7O1q0aCG2tWjRAu7u7nB3d69W4UarIzcREREIDg5GWFgYPD09sWzZMvj6+uL69euwtrbO1/+bb77Bxo0b8dNPP8HFxQUHDx5Ev379cPLkSbRs2VILW0BE1RlHHDSDIw6VU1V++KhMEARBWyv39PTEu+++ixUrVgAAVCoV7O3t8dlnn2HKlCn5+tvZ2WHq1KkYP3682Na/f38YGRlh48aNJVpneno6LCwskJaWBnPzwp87QkRUnBkzZvAch9KYYVHk7KxcAabzMwAAmSFmMDGQFdm/ef16GivtFW1fwqwJWVlZMDU1BQBkZmYW+7iEwi4FT9qVlO/ho68r6uGj5bEfS/P3W2sjN7m5uYiNjUVISIjYpqOjgy5duuDUqVMFLpOTkwNDQ0O1NiMjI8TExBS6npycHOTk5IjT6enpb1k5EdFLHHEgrSgmJCL3tTGLuQqgmJCIQkJiVX74qNYqe/z4MZRKJWxs1FOfjY0Nrl27VuAyvr6+WLJkCby9veHk5ISoqCjs3LkTSqWy0PXMnz+/yP+siIjKqio/WLAySchQISFTwLO8f/8on09Uwkj/5R9lhakMCjOtnyJa7VTlh49W3thVgOXLl2PUqFFwcXGBTCaDk5MTAgMDsXbt2kKXCQkJQXBwsDidnp4Oe3v7iiiXiKjUquN5PKtjczHzaK5aW/t12eLXoT4GmNHR8M3FiAqltXBTu3Zt6OrqIikpSa09KSkJtra2BS5jZWWF3bt34/nz53jy5Ans7OwwZcoUNGjQoND1yOVyyOVyjdZORNWMpg8DzEgrdFZ1vFfJGA8D9HYufIRAYVrM/iQAHAF7ndbCjYGBATw8PBAVFYW+ffsCeHlCcVRUFCZMmFDksoaGhqhTpw7y8vLwyy+/YMCAARVQMRFR+auO5/EozHSgMNN2FVUfR8D+pdXDUsHBwQgICECrVq3QunVrLFu2DFlZWQgMDAQA+Pv7o06dOpg/fz4A4PTp03jw4AFatGiBBw8eYMaMGVCpVJg8ebI2N4OISGN4Hg+VFUfA/qXVcOPn54fk5GRMnz4diYmJaNGiBSIjI8WTjOPj46Gj8+8Q2vPnz/HNN9/gzp07MDU1xfvvv48NGzbA0tJSS1tARNVZWQ8DFPcUZqD0T2KWwiXM9HY4AvYvrZ9QPGHChEIPQ0VHR6tN+/j44O+//66AqoiIisfDAESVk9bDDRFRVVUehwGq8l1hiSoLhhsiojIqj8MAKUdS8t0VNm5unPh1UXeFJaKXGG6IiCqRqnxXWKLKgj8lRNVQdbxRXFVRle8KS1RZMNwQVUPV8UZxRFR9MNwQVUPV8UZxRFR9MNwQVUO8URwRSRnDDZGUVeAzkYiIKovq8QQtIiIiqjY4ckNUDfHpwUQkZQw3RNUQHxtARFLGcENUDfHpwUQkZQw3RNUQnx5MRFLGg+pEREQkKQw3REREJCkMN0RERCQpDDdEREQkKTyhmKoUPs2aiIiKw3BDVQqfZk1ERMVhuKEqhU+zJiKi4jDcUJXCp1kTEVFxGG6ocuLTrImIqIx4tRQRERFJCsMNERERSQoPS1GVkpChQkKmgGd5/x6WOp+ohJH+y8NSClMZFGbM7ERE1RnDDVUpq2NzMfNorlpb+3XZ4tehPgaY0dGwossiIqJKhOGGqpQxHgbo7axf6HyFaTEnFhMRkeQx3FCVojDTgcJM21UQEVFlxpMTiIiISFI4ckNEGsHnfhFRZcFwU0H4i5+kjs/9IqLKguGmgvAXP0kdn/tFRJUFw00F4S9+koLm4c2L7aPKUYlfj74yGjry/39q36WC+18KKGQGEVEZMdxUED7wkYiIqGIw3BCRRuSl5uFF6guo8v4duXkW/ww6+i9HbvQs9aBvWfg9ioiINIXhhog0IuVICpL3JKu1xc2NE7+26mMFm342FV0WEVVDDDdEpBE1O9WEeUvzQufrWfLXDRFVDP62ISKN0LfU52EnIqoUGG40bYZF0fNz/32aNeYqAINinoU0I+3tayIiIqpG+PgFIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFF4KXkESMlRIyBTwLO/fS8HPJyphpP/yUnCFqQwKM2ZNIiKit8VwU0FWx+Zi5tFctbb267LFr0N9DDCjo2FFl0VERCQ5DDcVZIyHAXo7F373VoVpMTfzIyIiohJhuKkgCjMdKMy0XQUREZH08SQPIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUrYeblStXwtHREYaGhvD09MSZM2eK7L9s2TI4OzvDyMgI9vb2+OKLL/D8+fMKqpaIiIgqO62Gm4iICAQHByM0NBRnz56Fm5sbfH198ejRowL7b968GVOmTEFoaCiuXr2KNWvWICIiAv/5z38quHIiIiKqrLQabpYsWYJRo0YhMDAQTZs2RVhYGIyNjbF27doC+588eRLt2rXDJ598AkdHR3Tr1g2DBg0qdrSHiIiIqg89ba04NzcXsbGxCAkJEdt0dHTQpUsXnDp1qsBl2rZti40bN+LMmTNo3bo17ty5gwMHDmDo0KGFricnJwc5OTnidHp6uuY2giQhISEBCQkJhc5XKBRQKBQVWBEREb0NrYWbx48fQ6lUwsbGRq3dxsYG165dK3CZTz75BI8fP0b79u0hCAJevHiBsWPHFnlYav78+Zg5c6ZGaydpWb16dZGfkdDQUMyYMaPiCiIiorei9ROKSyM6Ohrz5s3DDz/8gLNnz2Lnzp3Yv38/Zs+eXegyISEhSEtLE1/379+vwIqpKhgzZgxiY2MRExMjtsXExCA2NhaxsbEYM2aMFqsjIqLS0trITe3ataGrq4ukpCS19qSkJNja2ha4zLRp0zB06FCMHDkSANC8eXNkZWVh9OjRmDp1KnR08mc1uVwOuVyu+Q0gyXh12CkrK0tsa9GiBUxMTLRYFRERlZXWRm4MDAzg4eGBqKgosU2lUiEqKgpeXl4FLpOdnZ0vwOjq6gIABEEov2KJiIioytDayA0ABAcHIyAgAK1atULr1q2xbNkyZGVlITAwEADg7++POnXqYP78+QCAXr16YcmSJWjZsiU8PT1x69YtTJs2Db169RJDDhEREVVvWg03fn5+SE5OxvTp05GYmIgWLVogMjJSPMk4Pj5ebaTmm2++gUwmwzfffIMHDx7AysoKvXr1wty5c7W1CURERFTJaDXcAMCECRMwYcKEAudFR0erTevp6SE0NBShoaEVUBkRERFVRVXqaikiIiKi4pQp3Lx48QK///47Vq9ejYyMDADAw4cPkZmZqdHiiIiIiEqr1Iel7t27h+7duyM+Ph45OTno2rUrzMzMsGDBAuTk5CAsLKw86iQiIiIqkVKP3AQFBaFVq1Z4+vQpjIyMxPZ+/fqpXdZNREREpA2lHrk5fvw4Tp48CQMDA7V2R0dHPHjwQGOFEREREZVFqcONSqWCUqnM1/7PP//AzMxMI0URaVrz8ObF9lHlqMSvW29qDR150QOblwIuvXVdRESkeaU+LNWtWzcsW7ZMnJbJZMjMzERoaCjef/99TdZGREREVGqlHrlZtGgRunfvjqZNm+L58+f45JNPcPPmTdSuXRtbtmwpjxqJiIiISqzU4cbe3h4XLlxAREQELly4gMzMTIwYMQKDBw9WO8GYiIiISBtKFW7y8vLg4uKCX3/9FYMHD8bgwYPLqy4iIiKiMinVOTf6+vp4/vx5edVCRERE9NZKfULx+PHjsWDBArx48aI86iEiIiJ6K6U+5+bPP/9EVFQUDh06hObNm8PExERt/s6dOzVWHBEREVFplTrcWFpaon///uVRCxEREdFbK3W4WbduXXnUQURERKQRpQ43ryQnJ+P69esAAGdnZ1hZWWmsKKKKlJeahxepL6DK+/cOxc/in0FH/+UpaXqWetC31NdWeUREVEqlDjdZWVn47LPP8PPPP0OlevnHQFdXF/7+/vj+++9hbGys8SKJylPKkRQk70lWa4ubGyd+bdXHCjb9bCq6LCIiKqNSh5vg4GAcPXoU+/btQ7t27QAAMTEx+Pzzz/Hll19i1apVGi+SqDzV7FQT5i3NC52vZ1nmAU4iItKCUv/W/uWXX7Bjxw507NhRbHv//fdhZGSEAQMGMNxQlaNvqc/DTkREElLq+9xkZ2fDxib/EL21tTWys7M1UhQRERFRWZU63Hh5eSE0NFTtTsXPnj3DzJkz4eXlpdHiiIiIiEqr1Ielli9fDl9fX9StWxdubm4AgAsXLsDQ0BAHDx7UeIFEREREpVHqcOPq6oqbN29i06ZNuHbtGgBg0KBBfCo4ERERVQplugzE2NgYo0aN0nQtRERERG+t1OfczJ8/H2vXrs3XvnbtWixYsEAjRRERERGVVanDzerVq+Hi4pKvvVmzZggLC9NIUURERERlVepwk5iYCIVCka/dysoKCQkJGimKiIiIqKxKHW7s7e1x4sSJfO0nTpyAnZ2dRooiIiIiKqtSn1A8atQoTJw4EXl5eejcuTMAICoqCpMnT8aXX36p8QKJiIiISqPU4WbSpEl48uQJPv30U+Tm5gIADA0N8fXXXyMkJETjBRIRERGVRqnDjUwmw4IFCzBt2jRcvXoVRkZGaNSoEeRyeXnUR0RERFQqpT7n5hVTU1O8++67MDMzw+3bt6FSqTRZFxEREVGZlDjcrF27FkuWLFFrGz16NBo0aIDmzZvD1dUV9+/f13iBRERERKVR4nDz448/okaNGuJ0ZGQk1q1bh59//hl//vknLC0tMXPmzHIpkoiIiKikSnzOzc2bN9GqVStxes+ePejTpw8GDx4MAJg3bx4CAwM1XyERERFRKZR45ObZs2cwNzcXp0+ePAlvb29xukGDBkhMTNRsdURERESlVOJw4+DggNjYWADA48ePceXKFbRr106cn5iYCAsLC81XSERERFQKJT4sFRAQgPHjx+PKlSv4v//7P7i4uMDDw0Ocf/LkSbi6upZLkUREREQlVeJwM3nyZGRnZ2Pnzp2wtbXF9u3b1eafOHECgwYN0niBRERERKVR4nCjo6ODWbNmYdasWQXOfzPsEBEREWlDmW/iR0RERFQZMdwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpGgs3Ny/fx/Dhw/X1NsRERERlYnGwk1KSgrCw8M19XZEREREZVLi+9zs3bu3yPl37tx562KIiIiI3laJw03fvn0hk8kgCEKhfWQymUaKIiIiIiqrEh+WUigU2LlzJ1QqVYGvs2fPlmedRERERCVS4pEbDw8PxMbGok+fPgXOL25UhzQvISEBCQkJhc5XKBRQKBQVWBEREZH2lTjcTJo0CVlZWYXOb9iwIY4cOaKRoqhkVq9ejZkzZxY6PzQ0FDNmzKi4goiIiCqBEoebDh06FDnfxMQEPj4+b10QldyYMWPQu3dvPHv2DO3btwcAxMTEwMjICAA4akNERNVSicPNnTt3UL9+fZ40XIm8Ouz0+ohaixYtYGJiosWqiIiItKvEJxQ3atQIycnJ4rSfnx+SkpLKpSgiIiKisipxuHnzZOEDBw4UeQ4OERERkTbw2VJEREQkKSUONzKZLN/5Njz/hoiIiCqbEp9QLAgChg0bBrlcDgB4/vw5xo4dm+/k1Z07d2q2QiIiIqJSKHG4CQgIUJseMmSIxoshIiIielslDjfr1q0rzzqIiIiINIInFBMREZGkMNwQERGRpFSKcLNy5Uo4OjrC0NAQnp6eOHPmTKF9O3bsKF659fqrZ8+eFVgxERERVVZaDzcREREIDg5GaGgozp49Czc3N/j6+uLRo0cF9t+5c6f4NOyEhARcvnwZurq6+Pjjjyu4ciIiIqqMtB5ulixZglGjRiEwMBBNmzZFWFgYjI2NsXbt2gL716xZE7a2tuLr8OHDMDY2ZrghIiIiAKW4Wqo85ObmIjY2FiEhIWKbjo4OunTpglOnTpXoPdasWYOBAwcW+rDInJwc5OTkiNPp6elvV3QFax7evNg+qhyV+HXrTa2hIy86s14KuPTWdREREVVWWh25efz4MZRKJWxsbNTabWxskJiYWOzyZ86cweXLlzFy5MhC+8yfPx8WFhbiy97e/q3rJiIiospL64el3saaNWvQvHlztG7dutA+ISEhSEtLE1/379+vwAqJiIioomn1sFTt2rWhq6uLpKQktfakpCTY2toWuWxWVha2bt2KWbNmFdlPLpeLj4wgIiIi6dPqyI2BgQE8PDwQFRUltqlUKkRFRcHLy6vIZbdv346cnBw+BoKIiIjUaHXkBgCCg4MREBCAVq1aoXXr1li2bBmysrIQGBgIAPD390edOnUwf/58teXWrFmDvn37olatWtoom4iIiCoprYcbPz8/JCcnY/r06UhMTESLFi0QGRkpnmQcHx8PHR31Aabr168jJiYGhw4d0kbJREREVIlpPdwAwIQJEzBhwoQC50VHR+drc3Z2hiAI5VwVERERVUVV+mopIiIiojcx3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpFSKS8GpbPJS8/Ai9QVUef8+FfxZ/DPo6L/MrHqWetC31NdWeURERFrBcFOFpRxJQfKeZLW2uLlx4tdWfaxg08/mzcWIiIgkjeGmCqvZqSbMW5oXOl/Pkt9eIiKqfvjXrwrTt9TnYSciIqI38IRiIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUrYeblStXwtHREYaGhvD09MSZM2eK7J+amorx48dDoVBALpejcePGOHDgQAVVS0RERJWdnjZXHhERgeDgYISFhcHT0xPLli2Dr68vrl+/Dmtr63z9c3Nz0bVrV1hbW2PHjh2oU6cO7t27B0tLy4ovnoiIiColrYabJUuWYNSoUQgMDAQAhIWFYf/+/Vi7di2mTJmSr//atWuRkpKCkydPQl9fHwDg6OhYkSUTERFRJae1w1K5ubmIjY1Fly5d/i1GRwddunTBqVOnClxm79698PLywvjx42FjYwNXV1fMmzcPSqWy0PXk5OQgPT1d7UVERETSpbVw8/jxYyiVStjY2Ki129jYIDExscBl7ty5gx07dkCpVOLAgQOYNm0aFi9ejDlz5hS6nvnz58PCwkJ82dvba3Q7iIiIqHLR+gnFpaFSqWBtbY0ff/wRHh4e8PPzw9SpUxEWFlboMiEhIUhLSxNf9+/fr8CKiYiIqKJp7Zyb2rVrQ1dXF0lJSWrtSUlJsLW1LXAZhUIBfX196Orqim1NmjRBYmIicnNzYWBgkG8ZuVwOuVyu2eKJiIio0tLayI2BgQE8PDwQFRUltqlUKkRFRcHLy6vAZdq1a4dbt25BpVKJbTdu3IBCoSgw2BAREVH1o9XDUsHBwfjpp58QHh6Oq1evYty4ccjKyhKvnvL390dISIjYf9y4cUhJSUFQUBBu3LiB/fv3Y968eRg/fry2NoGIiIgqGa1eCu7n54fk5GRMnz4diYmJaNGiBSIjI8WTjOPj46Gj82/+sre3x8GDB/HFF1/gnXfeQZ06dRAUFISvv/5aW5tARERElYxWww0ATJgwARMmTChwXnR0dL42Ly8v/PHHH+VcFREREVVVVepqKSIiIqLiMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpDDcEBERkaQw3BAREZGkMNwQERGRpFSKcLNy5Uo4OjrC0NAQnp6eOHPmTKF9169fD5lMpvYyNDSswGqJiIioMtN6uImIiEBwcDBCQ0Nx9uxZuLm5wdfXF48ePSp0GXNzcyQkJIive/fuVWDFREREVJlpPdwsWbIEo0aNQmBgIJo2bYqwsDAYGxtj7dq1hS4jk8lga2srvmxsbCqwYiIiIqrMtBpucnNzERsbiy5duohtOjo66NKlC06dOlXocpmZmXBwcIC9vT369OmDK1euVES5REREVAXoaXPljx8/hlKpzDfyYmNjg2vXrhW4jLOzM9auXYt33nkHaWlpWLRoEdq2bYsrV66gbt26+frn5OQgJydHnE5LSwMApKena3BLXl+hoNG3Uz5TavT9gHLcdk3iftQM7kfN4H7UDO5Hzaim+/HVewpCCbZf0KIHDx4IAISTJ0+qtU+aNElo3bp1id4jNzdXcHJyEr755psC54eGhgoA+OKLL7744osvCbzu379fbDbQ6shN7dq1oauri6SkJLX2pKQk2Nralug99PX10bJlS9y6davA+SEhIQgODhanVSoVUlJSUKtWLchksrIX/xbS09Nhb2+P+/fvw9zcXCs1SAH3o2ZwP2oG96NmcD9qhhT3oyAIyMjIgJ2dXbF9tRpuDAwM4OHhgaioKPTt2xfAy/ARFRWFCRMmlOg9lEolLl26hPfff7/A+XK5HHK5XK3N0tLybcrWGHNzc8l86LSJ+1EzuB81g/tRM7gfNUNq+9HCwqJE/bQabgAgODgYAQEBaNWqFVq3bo1ly5YhKysLgYGBAAB/f3/UqVMH8+fPBwDMmjULbdq0QcOGDZGamopvv/0W9+7dw8iRI7W5GURERFRJaD3c+Pn5ITk5GdOnT0diYiJatGiByMhI8STj+Ph46Oj8e1HX06dPMWrUKCQmJqJGjRrw8PDAyZMn0bRpU21tAhEREVUiWg83ADBhwoRCD0NFR0erTS9duhRLly6tgKrKj1wuR2hoaL7DZVQ63I+awf2oGdyPmsH9qBnVfT/KBKEk11QRERERVQ1av0MxERERkSYx3BAREZGkMNwQERGRpDDcEBERkaQw3GjJf//7X8hkMkycOFHbpVQ5SqUS06ZNQ/369WFkZAQnJyfMnj27ZM8bqcaOHTuGXr16wc7ODjKZDLt3787X5+rVq+jduzcsLCxgYmKCd999F/Hx8RVfbCW1atUqvPPOO+KN0by8vPDbb78BAFJSUvDZZ5/B2dkZRkZGqFevHj7//HPxeXak7sGDBxgyZAhq1aoFIyMjNG/eHH/99VeBfceOHQuZTIZly5ZVbJFVQEZGBiZOnAgHBwcYGRmhbdu2+PPPP8X5giBg+vTpUCgUMDIyQpcuXXDz5k0tVlwxGG604M8//8Tq1avxzjvvaLuUKmnBggVYtWoVVqxYgatXr2LBggVYuHAhvv/+e22XVqllZWXBzc0NK1euLHD+7du30b59e7i4uCA6OhoXL17EtGnTYGhoWMGVVl5169bFf//7X8TGxuKvv/5C586d0adPH1y5cgUPHz7Ew4cPsWjRIly+fBnr169HZGQkRowYoe2yK52nT5+iXbt20NfXx2+//Ya///4bixcvRo0aNfL13bVrF/74448S3XK/Oho5ciQOHz6MDRs24NKlS+jWrRu6dOmCBw8eAAAWLlyI7777DmFhYTh9+jRMTEzg6+uL58+fa7nyclaip1OSxmRkZAiNGjUSDh8+LPj4+AhBQUHaLqnK6dmzpzB8+HC1tg8//FAYPHiwliqqegAIu3btUmvz8/MThgwZop2CqrAaNWoI//vf/wqct23bNsHAwEDIy8ur4Koqt6+//lpo3759sf3++ecfoU6dOsLly5cFBwcHYenSpeVfXBWSnZ0t6OrqCr/++qtau7u7uzB16lRBpVIJtra2wrfffivOS01NFeRyubBly5aKLrdCceSmgo0fPx49e/ZEly5dtF1KldW2bVtERUXhxo0bAIALFy4gJiYGPXr00HJlVZdKpcL+/fvRuHFj+Pr6wtraGp6engUeuqKXlEoltm7diqysLHh5eRXYJy0tDebm5tDTqxT3S6009u7di1atWuHjjz+GtbU1WrZsiZ9++kmtj0qlwtChQzFp0iQ0a9ZMS5VWbi9evIBSqcw3umpkZISYmBjExcUhMTFR7e+NhYUFPD09cerUqYout0Ix3FSgrVu34uzZs+JzsqhspkyZgoEDB8LFxUV8KvzEiRMxePBgbZdWZT169AiZmZn473//i+7du+PQoUPo168fPvzwQxw9elTb5VUqly5dgqmpKeRyOcaOHYtdu3YV+PiXx48fY/bs2Rg9erQWqqzc7ty5g1WrVqFRo0Y4ePAgxo0bh88//xzh4eFinwULFkBPTw+ff/65Fiut3MzMzODl5YXZs2fj4cOHUCqV2LhxI06dOoWEhAQkJiYCgPg4o1dsbGzEeVLFfycqyP379xEUFITDhw/zHIa3tG3bNmzatAmbN29Gs2bNcP78eUycOBF2dnYICAjQdnlVkkqlAgD06dMHX3zxBQCgRYsWOHnyJMLCwuDj46PN8ioVZ2dnnD9/HmlpadixYwcCAgJw9OhRtYCTnp6Onj17omnTppgxY4b2iq2kVCoVWrVqhXnz5gEAWrZsicuXLyMsLAwBAQGIjY3F8uXLcfbsWchkMi1XW7lt2LABw4cPR506daCrqwt3d3cMGjQIsbGx2i5NqzhyU0FiY2Px6NEjuLu7Q09PD3p6ejh69Ci+++476OnpQalUarvEKmPSpEni6E3z5s0xdOhQfPHFFxwRewu1a9eGnp5evhGIJk2a8GqpNxgYGKBhw4bw8PDA/Pnz4ebmhuXLl4vzMzIy0L17d5iZmWHXrl3Q19fXYrWVk0KhKPKzdvz4cTx69Aj16tUTf1/eu3cPX375JRwdHbVQceXl5OSEo0ePIjMzE/fv38eZM2eQl5eHBg0awNbWFgCQlJSktkxSUpI4T6o4clNB3nvvPVy6dEmtLTAwEC4uLvj666+hq6urpcqqnuzsbLUnxQOArq6uOPpApWdgYIB3330X169fV2u/ceMGHBwctFRV1aBSqZCTkwPg5YiNr68v5HI59u7dy1HaQrRr167Iz9rQoUPznZfo6+uLoUOHIjAwsMLqrEpMTExgYmKCp0+f4uDBg1i4cCHq168PW1tbREVFoUWLFgBefkZPnz6NcePGabfgcsZwU0HMzMzg6uqq1mZiYoJatWrla6ei9erVC3PnzkW9evXQrFkznDt3DkuWLMHw4cO1XVqllpmZiVu3bonTcXFxOH/+PGrWrIl69eph0qRJ8PPzg7e3Nzp16oTIyEjs27cP0dHR2iu6kgkJCUGPHj1Qr149ZGRkYPPmzYiOjsbBgweRnp6Obt26ITs7Gxs3bkR6ejrS09MBAFZWVvwH5jVffPEF2rZti3nz5mHAgAE4c+YMfvzxR/z4448AgFq1aqFWrVpqy+jr68PW1hbOzs7aKLnSOnjwIARBgLOzM27duoVJkybBxcUFgYGB4r3U5syZg0aNGqF+/fqYNm0a7Ozs0LdvX22XXr60fblWdcZLwcsmPT1dCAoKEurVqycYGhoKDRo0EKZOnSrk5ORou7RK7ciRIwKAfK+AgACxz5o1a4SGDRsKhoaGgpubm7B7927tFVwJDR8+XHBwcBAMDAwEKysr4b333hMOHTokCELh+xeAEBcXp93CK6F9+/YJrq6uglwuF1xcXIQff/yxyP68FLxgERERQoMGDQQDAwPB1tZWGD9+vJCamirOV6lUwrRp0wQbGxtBLpcL7733nnD9+nUtVlwxZILA27oSERGRdPCEYiIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsikgyZTIbdu3eX6zpmzJgh3sqeiConhhsiKrHk5GSMGzcO9erVg1wuh62tLXx9fXHixAltl6Yxu3btQps2bWBhYQEzMzM0a9YMEydOFOd/9dVXiIqK0l6BRFQsPluKiEqsf//+yM3NRXh4OBo0aICkpCRERUXhyZMn2i5NI6KiouDn54e5c+eid+/ekMlk+Pvvv3H48GGxj6mpKUxNTbVYJREVS9vPfyCiquHp06cCACE6OrrIfosXLxZcXV0FY2NjoW7dusK4ceOEjIwMcf66desECwsLYd++fULjxo0FIyMjoX///kJWVpawfv16wcHBQbC0tBQ+++wz4cWLF+JyDg4OwqxZs4SBAwcKxsbGgp2dnbBixQq1dQMQdu3aJU7Hx8cLH3/8sWBhYSHUqFFD6N27d5HPeQoKChI6duxY5PaFhoYKbm5uaut88+Xg4CDOv3TpktC9e3fBxMREsLa2FoYMGSIkJycXuQ4iejs8LEVEJfJqxGL37t3IyckptJ+Ojg6+++47XLlyBeHh4fi///s/TJ48Wa1PdnY2vvvuO2zduhWRkZGIjo5Gv379cODAARw4cAAbNmzA6tWrsWPHDrXlvv32W7i5ueHcuXOYMmUKgoKC1EZVXpeXlwdfX1+YmZnh+PHjOHHiBExNTdG9e3fk5uYWuIytrS2uXLmCy5cvl3i/JCQkiK9bt26hYcOG8Pb2BgCkpqaic+fOaNmyJf766y9ERkYiKSkJAwYMKPH7E1EZaDtdEVHVsWPHDqFGjRqCoaGh0LZtWyEkJES4cOFCkcts375dqFWrlji9bt06AYBw69YtsW3MmDGCsbGx2giPr6+vMGbMGHHawcFB6N69u9p7+/n5CT169BCn8drIzYYNGwRnZ2dBpVKJ83NycgQjIyPh4MGDBdaamZkpvP/+++Loi5+fn7BmzRrh+fPnYp83R25eUalUQr9+/QQPDw8hOztbEARBmD17ttCtWze1fvfv3xcAVIsnMxNpC0duiKjE+vfvj4cPH2Lv3r3o3r07oqOj4e7ujvXr14t9fv/9d7z33nuoU6cOzMzMMHToUDx58gTZ2dliH2NjYzg5OYnTNjY2cHR0VDuXxcbGBo8ePVJbv5eXV77pq1evFljrhQsXcOvWLZiZmYmjTjVr1sTz589x+/btApcxMTHB/v37cevWLXzzzTcwNTXFl19+idatW6vVX5D//Oc/OHXqFPbs2QMjIyOxhiNHjojrNzU1hYuLCwAUWgMRvT2eUExEpWJoaIiuXbuia9eumDZtGkaOHInQ0FAMGzYMd+/exQcffIBx48Zh7ty5qFmzJmJiYjBixAjk5ubC2NgYAKCvr6/2njKZrMA2lUpV5jozMzPh4eGBTZs25ZtnZWVV5LJOTk5wcnLCyJEjMXXqVDRu3BgREREIDAwssP/GjRuxdOlSREdHo06dOmo19OrVCwsWLMi3jEKhKOUWEVFJMdwQ0Vtp2rSpeG+Z2NhYqFQqLF68GDo6LweGt23bprF1/fHHH/mmmzRpUmBfd3d3REREwNraGubm5mVep6OjI4yNjZGVlVXg/FOnTmHkyJFYvXo12rRpk6+GX375BY6OjtDT469boorCw1JEVCJPnjxB586dsXHjRly8eBFxcXHYvn07Fi5ciD59+gAAGjZsiLy8PHz//fe4c+cONmzYgLCwMI3VcOLECSxcuBA3btzAypUrsX37dgQFBRXYd/Dgwahduzb69OmD48ePIy4uDtHR0fj888/xzz//FLjMjBkzMHnyZERHRyMuLg7nzp3D8OHDkZeXh65du+brn5iYiH79+mHgwIHw9fVFYmIiEhMTkZycDAAYP348UlJSMGjQIPz555+4ffs2Dh48iMDAQCiVSo3tFyJSx3BDRCViamoKT09PLF26FN7e3nB1dcW0adMwatQorFixAgDg5uaGJUuWYMGCBXB1dcWmTZswf/58jdXw5Zdf4q+//kLLli0xZ84cLFmyBL6+vgX2NTY2xrFjx1CvXj18+OGHaNKkCUaMGIHnz58XOpLj4+ODO3fuwN/fHy4uLujRowcSExNx6NAhODs75+t/7do1JCUlITw8HAqFQny9++67AAA7OzucOHECSqUS3bp1Q/PmzTFx4kRYWlqKI1tEpHkyQRAEbRdBRFQcR0dHTJw4Ue1uwUREBeG/DkRERCQpDDdEREQkKTwsRURERJLCkRsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpIUhhsiIiKSFIYbIiIikhSGGyIiIpKU/wf7lX2G79fugwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "set_of_samples = [4, 8, 16, 32, 64, 90]\n",
    "\n",
    "# Calculate the mean and variance of F1 scores for each sample size\n",
    "\n",
    "\n",
    "mean_f1_scores_hybrid = np.mean(F1_score_hybrid, axis=0)\n",
    "variance_f1_scores_hybrid = np.var(F1_score_hybrid, axis=0)\n",
    "\n",
    "mean_f1_scores_ae = np.mean(F1_score_finetuned, axis=0)\n",
    "variance_f1_scores_ae= np.var(F1_score_finetuned, axis=0)\n",
    "\n",
    "# Set the width of each bar\n",
    "bar_width = 0.25\n",
    "\n",
    "# Create an array representing the x-axis positions\n",
    "x = np.arange(len(set_of_samples))\n",
    "\n",
    "# Choose colors for three classes\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "\n",
    "# Create side-by-side bar plots with error bars\n",
    "plt.bar(x, mean_f1_scores_hybrid, bar_width, yerr=np.sqrt(variance_f1_scores_hybrid), capsize=3, color=colors[1], label='hybrid')\n",
    "plt.bar(x + bar_width, mean_f1_scores_ae, bar_width, yerr=np.sqrt(variance_f1_scores_ae), capsize=3, color=colors[2], label='SOAT2')\n",
    "\n",
    "plt.grid(visible=False)\n",
    "plt.legend()\n",
    "plt.xlabel('Sample Size')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.ylim([0.5,1])\n",
    "plt.title('F1 Score vs. Sample Size with Variance')\n",
    "plt.xticks(x, [str(x) for x in set_of_samples])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
